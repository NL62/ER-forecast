2025-12-10 16:21:20,234 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.30.51.137:5000
2025-12-10 16:21:20,234 [INFO] [33mPress CTRL+C to quit[0m
2025-12-10 16:21:20,235 [INFO]  * Restarting with stat
2025-12-10 16:21:20,374 [WARNING]  * Debugger is active!
2025-12-10 16:21:20,376 [INFO]  * Debugger PIN: 541-460-208
2025-12-10 16:21:34,038 [INFO] Received /predict request
2025-12-10 16:21:34,080 [INFO] Prediction STDOUT:

2025-12-10 16:21:34,080 [ERROR] Prediction STDERR:
open /home/aexdafo/machine_learning/ER-forecast/ml_api/docker-compose.jobs.yml: no such file or directory

2025-12-10 16:21:34,080 [ERROR] Prediction command failed with exit code 1
2025-12-10 16:21:34,081 [INFO] 10.30.53.44 - - [10/Dec/2025 16:21:34] "GET /predict HTTP/1.1" 200 -
2025-12-10 16:22:07,602 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.30.51.137:5000
2025-12-10 16:22:07,602 [INFO] [33mPress CTRL+C to quit[0m
2025-12-10 16:22:07,602 [INFO]  * Restarting with stat
2025-12-10 16:22:07,740 [WARNING]  * Debugger is active!
2025-12-10 16:22:07,741 [INFO]  * Debugger PIN: 435-505-377
2025-12-10 16:22:33,758 [INFO]  * Detected change in '/home/aexdafo/machine_learning/ER-forecast/ml_api/api.py', reloading
2025-12-10 16:22:33,786 [INFO]  * Restarting with stat
2025-12-10 16:22:33,923 [WARNING]  * Debugger is active!
2025-12-10 16:22:33,924 [INFO]  * Debugger PIN: 435-505-377
2025-12-10 16:22:50,096 [INFO] Received /predict request
2025-12-10 16:23:00,312 [INFO] Prediction STDOUT:
2025-12-10 16:22:54,938 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-10 16:22:54,938 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-10 16:22:54,938 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-10 16:22:54,938 - __main__ - INFO - ======================================================================
2025-12-10 16:22:54,938 - __main__ - INFO - STARTING ER PATIENT FORECAST PREDICTION FLOW
2025-12-10 16:22:54,938 - __main__ - INFO - ======================================================================
2025-12-10 16:22:54,938 - __main__ - INFO - Prediction base date: 2025-12-10
2025-12-10 16:22:54,938 - __main__ - INFO - Output path: data/predictions/
2025-12-10 16:22:54,938 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:54,938 - __main__ - INFO - STEP 1: Loading Latest Patient Data
2025-12-10 16:22:54,938 - __main__ - INFO - ======================================================================
2025-12-10 16:22:54,938 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-10 16:22:54,939 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-10 16:22:56,590 - src.data.preprocessing - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:22:56,628 - __main__ - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:22:56,628 - src.data.preprocessing - INFO - Removing duplicates from 277,534 rows
2025-12-10 16:22:56,644 - src.data.preprocessing - WARNING - Found 200,196 duplicate rows (72.13%)
2025-12-10 16:22:56,647 - src.data.preprocessing - INFO - After removing duplicates: 77,338 rows remain
2025-12-10 16:22:56,649 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-10 16:22:56,711 - src.data.preprocessing - INFO - Aggregated to 1,287 days
2025-12-10 16:22:56,711 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-10 00:00:00
2025-12-10 16:22:56,711 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-10 16:22:56,711 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-10 16:22:56,711 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-10 16:22:56,713 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-10 16:22:56,715 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-10 16:22:56,718 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-10 16:22:56,718 - src.data.preprocessing - INFO - Final time series: 1,297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:22:56,718 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-10 16:22:56,719 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-10 16:22:56,719 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-10 16:22:56,719 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-10 16:22:56,719 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-10 16:22:56,719 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-10 16:22:56,720 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-10 16:22:56,721 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-10 16:22:56,721 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-10 16:22:56,721 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-10 16:22:56,721 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-10 16:22:56,721 - __main__ - INFO - Loaded data: 1297 days up to 2025-12-10
2025-12-10 16:22:56,721 - __main__ - INFO - Data validation passed: 1297 rows, most recent date 2025-12-10 (0 days ago)
2025-12-10 16:22:56,721 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:56,721 - __main__ - INFO - STEP 2: Fetching Weather Data (Historical + Forecast)
2025-12-10 16:22:56,721 - __main__ - INFO - ======================================================================
2025-12-10 16:22:56,722 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-10
2025-12-10 16:22:56,722 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:22:56,914 - src.data.weather_integration - INFO - Successfully fetched weather data: 1297 days
2025-12-10 16:22:56,915 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-10 16:22:56,916 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-10
2025-12-10 16:22:56,916 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-10
2025-12-10 16:22:56,917 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-10 16:22:56,918 - __main__ - INFO - Historical weather data: 1297 days
2025-12-10 16:22:56,918 - src.data.weather_integration - INFO - Fetching weather forecast for next 8 days
2025-12-10 16:22:56,918 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:22:57,077 - src.data.weather_integration - INFO - Successfully fetched weather forecast: 8 days
2025-12-10 16:22:57,078 - __main__ - INFO - Weather forecast fetched: 8 days
2025-12-10 16:22:57,078 - __main__ - INFO - Forecast date range: 2025-12-10 to 2025-12-17
2025-12-10 16:22:57,078 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:57,078 - __main__ - INFO - STEP 3: Engineering Features
2025-12-10 16:22:57,078 - __main__ - INFO - ======================================================================
2025-12-10 16:22:57,078 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-10 16:22:57,078 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-10 16:22:57,082 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-10 16:22:57,082 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-10 16:22:57,083 - src.data.feature_engineering - INFO - Weekend days: 370/1297 (28.5%)
2025-12-10 16:22:57,083 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-10 16:22:57,084 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-10 16:22:57,084 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Adding change features
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Added change features
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Final shape: (1297, 35)
2025-12-10 16:22:57,086 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-10 16:22:57,087 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-10 16:22:57,087 - src.data.feature_engineering - INFO - Rows with NaN: 28/1297 (2.2%)
2025-12-10 16:22:57,088 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-10 16:22:57,088 - src.data.feature_engineering - INFO - Remaining rows: 1269
2025-12-10 16:22:57,088 - __main__ - INFO - Features engineered: (1269, 35)
2025-12-10 16:22:57,088 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:57,088 - __main__ - INFO - STEP 4: Loading Production Models from MLflow
2025-12-10 16:22:57,088 - __main__ - INFO - ======================================================================
2025-12-10 16:22:57,088 - src.models.predict - INFO - Loading production models from MLflow Model Registry
2025-12-10 16:22:57,088 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_1
2025-12-10 16:22:57,153 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:57,466 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-10 16:22:57,587 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:22:57,587 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_1 v10
2025-12-10 16:22:57,587 - src.models.predict - INFO - Loaded model for horizon 1
2025-12-10 16:22:57,587 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_2
2025-12-10 16:22:57,641 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:57,808 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:22:57,809 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_2 v10
2025-12-10 16:22:57,809 - src.models.predict - INFO - Loaded model for horizon 2
2025-12-10 16:22:57,809 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_3
2025-12-10 16:22:57,904 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:58,070 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:22:58,070 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_3 v10
2025-12-10 16:22:58,070 - src.models.predict - INFO - Loaded model for horizon 3
2025-12-10 16:22:58,070 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_4
2025-12-10 16:22:58,163 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:58,328 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:22:58,328 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_4 v10
2025-12-10 16:22:58,328 - src.models.predict - INFO - Loaded model for horizon 4
2025-12-10 16:22:58,328 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_5
2025-12-10 16:22:58,421 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:58,586 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:22:58,587 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_5 v10
2025-12-10 16:22:58,587 - src.models.predict - INFO - Loaded model for horizon 5
2025-12-10 16:22:58,587 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_6
2025-12-10 16:22:58,680 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:58,845 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:22:58,845 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_6 v10
2025-12-10 16:22:58,845 - src.models.predict - INFO - Loaded model for horizon 6
2025-12-10 16:22:58,845 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_7
2025-12-10 16:22:58,938 - src.utils.mlflow_utils - INFO - Loading model version 10 from Production stage
2025-12-10 16:22:59,099 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:22:59,099 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_7 v10
2025-12-10 16:22:59,099 - src.models.predict - INFO - Loaded model for horizon 7
2025-12-10 16:22:59,099 - src.models.predict - INFO - Successfully loaded all 7 production models from MLflow
2025-12-10 16:22:59,099 - __main__ - INFO - Loaded 7 production models
2025-12-10 16:22:59,099 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:59,099 - __main__ - INFO - STEP 5: Preparing Prediction Features
2025-12-10 16:22:59,099 - __main__ - INFO - ======================================================================
2025-12-10 16:22:59,099 - src.models.predict - INFO - Preparing features for prediction
2025-12-10 16:22:59,099 - src.models.predict - INFO - Base date for predictions: 2025-12-10
2025-12-10 16:22:59,107 - src.models.predict - INFO - Prepared features for 7 prediction days
2025-12-10 16:22:59,107 - src.models.predict - INFO - Prediction date range: 2025-12-11 to 2025-12-17
2025-12-10 16:22:59,107 - src.models.predict - INFO - Weather forecasts applied to prediction features
2025-12-10 16:22:59,107 - src.models.predict - INFO - Total columns in prediction features: 35
2025-12-10 16:22:59,107 - __main__ - INFO - Features prepared for next 7 days
2025-12-10 16:22:59,107 - __main__ - INFO - Each horizon has weather forecast for its target date
2025-12-10 16:22:59,107 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:59,107 - __main__ - INFO - STEP 6: Generating Predictions with Confidence Intervals
2025-12-10 16:22:59,107 - __main__ - INFO - ======================================================================
2025-12-10 16:22:59,107 - src.models.predict - INFO - Generating batch predictions for next 7 days
2025-12-10 16:22:59,107 - src.models.predict - INFO - Feature columns selected: 33 features
2025-12-10 16:22:59,127 - src.models.predict - INFO - Generated 7 predictions
2025-12-10 16:22:59,127 - src.models.predict - INFO - Prediction range: 51.8 to 71.0 patients
2025-12-10 16:22:59,128 - src.monitoring.metrics_collector - INFO - Recorded prediction metrics: 7 predictions in 0.02s
2025-12-10 16:22:59,128 - __main__ - INFO - Generated 7 predictions in 0.02s
2025-12-10 16:22:59,129 - __main__ - INFO -    Prediction range: 51.8 to 71.0 patients
2025-12-10 16:22:59,129 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:59,129 - __main__ - INFO - STEP 7: Saving Predictions
2025-12-10 16:22:59,129 - __main__ - INFO - ======================================================================
2025-12-10 16:22:59,129 - src.models.prediction_output - INFO - Saving predictions to CSV
2025-12-10 16:22:59,132 - src.models.prediction_output - INFO - Predictions saved to: data/predictions/predictions_20251210_162259.csv
2025-12-10 16:22:59,132 - src.models.prediction_output - INFO - File size: 0.8 KB, Rows: 7
2025-12-10 16:22:59,132 - __main__ - INFO - Predictions saved to CSV: data/predictions/predictions_20251210_162259.csv
2025-12-10 16:22:59,132 - src.models.prediction_output - INFO - Writing predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:22:59,153 - src.models.prediction_output - INFO - Successfully wrote 7 predictions to [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:22:59,153 - __main__ - INFO - Wrote 7 predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:22:59,153 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:59,153 - __main__ - INFO - STEP 8: Logging Metadata to MLflow
2025-12-10 16:22:59,153 - __main__ - INFO - ======================================================================
2025-12-10 16:22:59,153 - src.models.prediction_output - INFO - Logging prediction metadata to MLflow
2025-12-10 16:22:59,884 - src.models.prediction_output - INFO - Prediction metadata logged to MLflow run: ddaa088b32a34e7392cacd5051892baa
üèÉ View run batch_prediction_2025-12-10_16:22:59 at: http://host.docker.internal:5050/#/experiments/2/runs/ddaa088b32a34e7392cacd5051892baa
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/2
2025-12-10 16:22:59,937 - __main__ - INFO - Logged to MLflow run: ddaa088b32a34e7392cacd5051892baa
2025-12-10 16:22:59,938 - __main__ - INFO - 
======================================================================
2025-12-10 16:22:59,938 - __main__ - INFO - PREDICTION FLOW COMPLETE! 
2025-12-10 16:22:59,938 - __main__ - INFO - ======================================================================
2025-12-10 16:22:59,938 - __main__ - INFO - Average prediction: 63.4 patients
2025-12-10 16:22:59,938 - __main__ - INFO - Average interval width: 37.65985452280102
2025-12-10 16:22:59,938 - src.monitoring.metrics_collector - INFO - Recorded flow run status: prediction_flow - success
2025-12-10 16:22:59,940 - __main__ - INFO - Prediction completed successfully: 7 predictions

2025-12-10 16:23:00,312 [ERROR] Prediction STDERR:
time="2025-12-10T16:22:50Z" level=warning msg="Found orphan containers ([er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.65ms
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 27594.11it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 24174.66it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 10364.84it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 7619.08it/s] 
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 5207.73it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 4984.91it/s]
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 110.70it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 167.06it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 224.50it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 272.68it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 339.70it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 338.49it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 30393.51it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 27776.85it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 416.20it/s]  
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 525.22it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 638.27it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 633.91it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 268.56it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 275.47it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 205.78it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 270.15it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 331.36it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 330.28it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 34379.54it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 29746.84it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 433.61it/s]  
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 526.82it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 603.05it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 596.85it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 96.64it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 127.58it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 182.27it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 241.97it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 301.90it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 301.14it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 33554.43it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 254.85it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 336.28it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 372.15it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 459.20it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 456.87it/s]
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
2025/12/10 16:22:59 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet


2025-12-10 16:23:00,312 [INFO] Prediction completed successfully
2025-12-10 16:23:00,312 [INFO] 10.30.53.44 - - [10/Dec/2025 16:23:00] "GET /predict HTTP/1.1" 200 -
2025-12-10 16:24:45,764 [INFO] 10.30.53.44 - - [10/Dec/2025 16:24:45] "[33mGET /training HTTP/1.1[0m" 404 -
2025-12-10 16:24:49,056 [INFO] Received /train request
2025-12-10 16:25:24,412 [INFO] Training STDOUT:
2025-12-10 16:24:53,942 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-10 16:24:53,942 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-10 16:24:53,942 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-10 16:24:53,942 - __main__ - INFO - ======================================================================
2025-12-10 16:24:53,942 - __main__ - INFO - STARTING ER PATIENT FORECAST TRAINING FLOW
2025-12-10 16:24:53,942 - __main__ - INFO - ======================================================================
2025-12-10 16:24:53,942 - __main__ - INFO - Raw data path: data/raw/emergency_visits.csv
2025-12-10 16:24:53,942 - __main__ - INFO - Horizons to train: [1, 2, 3, 4, 5, 6, 7]
2025-12-10 16:24:53,942 - __main__ - INFO - Optuna trials per horizon: 10
2025-12-10 16:24:53,942 - __main__ - INFO - MAE threshold for promotion: 15.0
2025-12-10 16:24:53,942 - __main__ - INFO - 
======================================================================
2025-12-10 16:24:53,942 - __main__ - INFO - STEP 1: Loading and Preprocessing Patient Data
2025-12-10 16:24:53,942 - __main__ - INFO - ======================================================================
2025-12-10 16:24:53,942 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-10 16:24:53,943 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-10 16:24:55,616 - src.data.preprocessing - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:24:55,657 - __main__ - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:24:55,657 - src.data.preprocessing - INFO - Removing duplicates from 277,534 rows
2025-12-10 16:24:55,674 - src.data.preprocessing - WARNING - Found 200,196 duplicate rows (72.13%)
2025-12-10 16:24:55,677 - src.data.preprocessing - INFO - After removing duplicates: 77,338 rows remain
2025-12-10 16:24:55,679 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-10 16:24:55,744 - src.data.preprocessing - INFO - Aggregated to 1,287 days
2025-12-10 16:24:55,744 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-10 00:00:00
2025-12-10 16:24:55,744 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-10 16:24:55,744 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-10 16:24:55,744 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-10 16:24:55,746 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-10 16:24:55,748 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-10 16:24:55,751 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-10 16:24:55,751 - src.data.preprocessing - INFO - Final time series: 1,297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:24:55,751 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-10 16:24:55,752 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-10 16:24:55,752 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-10 16:24:55,752 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-10 16:24:55,752 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-10 16:24:55,752 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-10 16:24:55,753 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-10 16:24:55,754 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-10 16:24:55,754 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-10 16:24:55,754 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-10 16:24:55,754 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-10 16:24:55,755 - __main__ - INFO - Preprocessed data: 1297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:24:55,755 - __main__ - INFO - 
======================================================================
2025-12-10 16:24:55,755 - __main__ - INFO - STEP 2: Fetching Weather Data
2025-12-10 16:24:55,755 - __main__ - INFO - ======================================================================
2025-12-10 16:24:55,755 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-10
2025-12-10 16:24:55,755 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:24:55,999 - src.data.weather_integration - INFO - Successfully fetched weather data: 1297 days
2025-12-10 16:24:56,000 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-10 16:24:56,002 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-10
2025-12-10 16:24:56,002 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-10
2025-12-10 16:24:56,003 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-10 16:24:56,003 - __main__ - INFO - Weather data merged: 1297 days of weather
2025-12-10 16:24:56,003 - __main__ - INFO - 
======================================================================
2025-12-10 16:24:56,003 - __main__ - INFO - STEP 3: Engineering Features
2025-12-10 16:24:56,003 - __main__ - INFO - ======================================================================
2025-12-10 16:24:56,003 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-10 16:24:56,003 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-10 16:24:56,006 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-10 16:24:56,006 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-10 16:24:56,007 - src.data.feature_engineering - INFO - Weekend days: 370/1297 (28.5%)
2025-12-10 16:24:56,008 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-10 16:24:56,009 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-10 16:24:56,009 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-10 16:24:56,010 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-10 16:24:56,010 - src.data.feature_engineering - INFO - Adding change features
2025-12-10 16:24:56,011 - src.data.feature_engineering - INFO - Added change features
2025-12-10 16:24:56,011 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-10 16:24:56,011 - src.data.feature_engineering - INFO - Final shape: (1297, 35)
2025-12-10 16:24:56,011 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-10 16:24:56,011 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-10 16:24:56,012 - src.data.feature_engineering - INFO - Rows with NaN: 28/1297 (2.2%)
2025-12-10 16:24:56,012 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-10 16:24:56,012 - src.data.feature_engineering - INFO - Remaining rows: 1269
2025-12-10 16:24:56,012 - __main__ - INFO - Feature engineering complete: 33 features, 1269 samples
2025-12-10 16:24:56,012 - __main__ - INFO - 
======================================================================
2025-12-10 16:24:56,012 - __main__ - INFO - STEP 4: Training Models for All Horizons
2025-12-10 16:24:56,012 - __main__ - INFO - ======================================================================
2025-12-10 16:24:56,012 - src.utils.mlflow_utils - INFO - Setting MLflow experiment: ER_Patient_Forecasting_MinIO
2025-12-10 16:24:56,024 - src.utils.mlflow_utils - INFO - Using experiment: ER_Patient_Forecasting_MinIO (ID: 1)
2025-12-10 16:24:56,024 - __main__ - INFO - Set experiment to: ER_Patient_Forecasting_MinIO (ID: 1)
2025-12-10 16:24:56,070 - __main__ - INFO - Current experiment artifact location: s3://mlflow-artifacts/1
2025-12-10 16:24:56,070 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:24:56,070 - __main__ - INFO - Training Horizon 1 Days Ahead
2025-12-10 16:24:56,070 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:24:56,070 - __main__ - INFO - Starting run: train_horizon_1_20251210_162456
2025-12-10 16:24:56,163 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:24:56,163 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/d4bf84c1a4a246cdbbaa79ace199fdb5/artifacts
2025-12-10 16:24:56,430 - src.models.train - INFO - Starting training for horizon 1 days
2025-12-10 16:24:56,430 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:24:56,430 - src.models.train - INFO - Creating shifted target for horizon=1 days
2025-12-10 16:24:56,431 - src.models.train - INFO - Created target for horizon 1: 1268 samples (1 rows removed due to shifting)
2025-12-10 16:24:56,432 - src.models.train - INFO - Data split: Train=760 (59.9%), Val=126 (9.9%), Calib=126 (9.9%), Test=256 (20.2%)
2025-12-10 16:24:56,432 - src.models.train - INFO - Features: 33
2025-12-10 16:24:56,433 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:24:56,434 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,434 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,561 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,563 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,564 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,590 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,593 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,593 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,667 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,669 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,669 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,720 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,722 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,722 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,761 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,763 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,763 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,884 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,886 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,886 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:56,960 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:56,962 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:56,962 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:57,032 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:57,035 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:57,035 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:57,168 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:57,171 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:57,171 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:57,191 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:57,193 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:24:57,193 - src.models.train - INFO - Best validation MAE: 6.5050
2025-12-10 16:24:57,193 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:24:57,193 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:24:57,193 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:24:57,193 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:24:57,270 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:24:57,270 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:24:57,270 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:24:57,270 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:24:57,335 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:24:57,335 - src.models.evaluation - INFO - Evaluating model on 256 test samples
2025-12-10 16:24:57,338 - src.models.evaluation - INFO - Evaluation: MAE=7.12, RMSE=9.54, Coverage=96.9%, Width=39.75
2025-12-10 16:24:57,338 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:24:57,338 - src.models.train - INFO -   MAE: 7.1188
2025-12-10 16:24:57,338 - src.models.train - INFO -   RMSE: 9.5393
2025-12-10 16:24:57,338 - src.models.train - INFO -   Coverage: 96.88%
2025-12-10 16:24:57,338 - src.models.train - INFO -   Interval Width: 39.75
2025-12-10 16:24:57,338 - src.models.train - INFO - Training complete for horizon 1
2025-12-10 16:24:57,348 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:24:57,658 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.5050, test_mae=7.1188, test_rmse=9.5393, test_coverage=0.9688, test_interval_width=39.7505
2025-12-10 16:24:57,658 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 1: MAE=7.12, RMSE=9.54
2025-12-10 16:24:57,658 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_1.pkl
2025-12-10 16:24:57,664 - src.models.lightgbm_model - INFO - Model saved successfully (556.0 KB)
2025-12-10 16:24:59,666 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-10 16:25:00,125 - __main__ - INFO - Model registered: er_forecast_horizon_1 v11
2025-12-10 16:25:00,125 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 1, stage Staging
2025-12-10 16:25:00,219 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:00,219 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:00,219 - src.models.model_promotion - INFO - Test MAE: 7.1188, Threshold: 15.0000
2025-12-10 16:25:00,219 - src.models.model_promotion - INFO - Model meets quality threshold (7.1188 < 15.0000)
2025-12-10 16:25:00,219 - __main__ - INFO - [PROMOTE] Model to production (MAE: 7.1188 < 15.0000)
2025-12-10 16:25:00,219 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_1 version 11
2025-12-10 16:25:00,314 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:00,410 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:00,504 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_1 v11
2025-12-10 16:25:00,504 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 1
2025-12-10 16:25:00,504 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 1, stage Production
üèÉ View run train_horizon_1_20251210_162456 at: http://host.docker.internal:5050/#/experiments/1/runs/d4bf84c1a4a246cdbbaa79ace199fdb5
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:00,605 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:00,605 - __main__ - INFO - Training Horizon 2 Days Ahead
2025-12-10 16:25:00,605 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:00,605 - __main__ - INFO - Starting run: train_horizon_2_20251210_162500
2025-12-10 16:25:00,654 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:00,654 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/f1ccfa58dcd24fbfa667316dc45ca736/artifacts
2025-12-10 16:25:00,924 - src.models.train - INFO - Starting training for horizon 2 days
2025-12-10 16:25:00,924 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:00,924 - src.models.train - INFO - Creating shifted target for horizon=2 days
2025-12-10 16:25:00,926 - src.models.train - INFO - Created target for horizon 2: 1267 samples (2 rows removed due to shifting)
2025-12-10 16:25:00,926 - src.models.train - INFO - Data split: Train=760 (60.0%), Val=126 (9.9%), Calib=126 (9.9%), Test=255 (20.1%)
2025-12-10 16:25:00,927 - src.models.train - INFO - Features: 33
2025-12-10 16:25:00,927 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:00,928 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:00,928 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,056 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,059 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,059 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,084 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,086 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,086 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,154 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,156 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,157 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,208 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,210 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,210 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,248 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,250 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,250 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,379 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,382 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,382 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,453 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,455 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,455 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,525 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,528 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,528 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,659 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,661 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,661 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,683 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,684 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:01,684 - src.models.train - INFO - Best validation MAE: 6.6484
2025-12-10 16:25:01,684 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:25:01,684 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:01,684 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:25:01,684 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:25:01,753 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:25:01,753 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:01,753 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:01,753 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:01,826 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:01,826 - src.models.evaluation - INFO - Evaluating model on 255 test samples
2025-12-10 16:25:01,829 - src.models.evaluation - INFO - Evaluation: MAE=6.98, RMSE=9.54, Coverage=95.3%, Width=35.37
2025-12-10 16:25:01,830 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:01,830 - src.models.train - INFO -   MAE: 6.9791
2025-12-10 16:25:01,830 - src.models.train - INFO -   RMSE: 9.5413
2025-12-10 16:25:01,830 - src.models.train - INFO -   Coverage: 95.29%
2025-12-10 16:25:01,830 - src.models.train - INFO -   Interval Width: 35.37
2025-12-10 16:25:01,830 - src.models.train - INFO - Training complete for horizon 2
2025-12-10 16:25:01,838 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:02,142 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6484, test_mae=6.9791, test_rmse=9.5413, test_coverage=0.9529, test_interval_width=35.3670
2025-12-10 16:25:02,142 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 2: MAE=6.98, RMSE=9.54
2025-12-10 16:25:02,143 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_2.pkl
2025-12-10 16:25:02,148 - src.models.lightgbm_model - INFO - Model saved successfully (579.5 KB)
2025-12-10 16:25:04,037 - __main__ - INFO - Model registered: er_forecast_horizon_2 v11
2025-12-10 16:25:04,037 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 2, stage Staging
2025-12-10 16:25:04,132 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:04,132 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:04,132 - src.models.model_promotion - INFO - Test MAE: 6.9791, Threshold: 15.0000
2025-12-10 16:25:04,132 - src.models.model_promotion - INFO - Model meets quality threshold (6.9791 < 15.0000)
2025-12-10 16:25:04,132 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9791 < 15.0000)
2025-12-10 16:25:04,132 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_2 version 11
2025-12-10 16:25:04,226 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:04,322 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:04,418 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_2 v11
2025-12-10 16:25:04,418 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 2
2025-12-10 16:25:04,418 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 2, stage Production
üèÉ View run train_horizon_2_20251210_162500 at: http://host.docker.internal:5050/#/experiments/1/runs/f1ccfa58dcd24fbfa667316dc45ca736
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:04,520 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:04,520 - __main__ - INFO - Training Horizon 3 Days Ahead
2025-12-10 16:25:04,520 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:04,520 - __main__ - INFO - Starting run: train_horizon_3_20251210_162504
2025-12-10 16:25:04,569 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:04,569 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/84ba9b25bd8442498dce73349b9dd90b/artifacts
2025-12-10 16:25:04,842 - src.models.train - INFO - Starting training for horizon 3 days
2025-12-10 16:25:04,842 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:04,842 - src.models.train - INFO - Creating shifted target for horizon=3 days
2025-12-10 16:25:04,844 - src.models.train - INFO - Created target for horizon 3: 1266 samples (3 rows removed due to shifting)
2025-12-10 16:25:04,844 - src.models.train - INFO - Data split: Train=759 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=255 (20.1%)
2025-12-10 16:25:04,845 - src.models.train - INFO - Features: 33
2025-12-10 16:25:04,845 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:04,846 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:04,846 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:04,975 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:04,978 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:04,978 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,006 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,008 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,008 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,081 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,083 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,083 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,136 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,138 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,138 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,178 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,180 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,180 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,306 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,308 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,308 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,384 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,386 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,386 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,457 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,460 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,460 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,587 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,589 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,589 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,611 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,612 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:05,612 - src.models.train - INFO - Best validation MAE: 6.6488
2025-12-10 16:25:05,613 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:25:05,613 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:05,613 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:25:05,613 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:25:05,685 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:05,685 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:05,685 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:05,685 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:05,750 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:05,750 - src.models.evaluation - INFO - Evaluating model on 255 test samples
2025-12-10 16:25:05,753 - src.models.evaluation - INFO - Evaluation: MAE=6.91, RMSE=9.52, Coverage=96.5%, Width=38.89
2025-12-10 16:25:05,753 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:05,753 - src.models.train - INFO -   MAE: 6.9126
2025-12-10 16:25:05,753 - src.models.train - INFO -   RMSE: 9.5154
2025-12-10 16:25:05,753 - src.models.train - INFO -   Coverage: 96.47%
2025-12-10 16:25:05,753 - src.models.train - INFO -   Interval Width: 38.89
2025-12-10 16:25:05,753 - src.models.train - INFO - Training complete for horizon 3
2025-12-10 16:25:05,762 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:06,075 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6488, test_mae=6.9126, test_rmse=9.5154, test_coverage=0.9647, test_interval_width=38.8899
2025-12-10 16:25:06,075 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 3: MAE=6.91, RMSE=9.52
2025-12-10 16:25:06,075 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_3.pkl
2025-12-10 16:25:06,081 - src.models.lightgbm_model - INFO - Model saved successfully (550.1 KB)
2025-12-10 16:25:07,960 - __main__ - INFO - Model registered: er_forecast_horizon_3 v11
2025-12-10 16:25:07,960 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 3, stage Staging
2025-12-10 16:25:08,055 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:08,055 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:08,055 - src.models.model_promotion - INFO - Test MAE: 6.9126, Threshold: 15.0000
2025-12-10 16:25:08,055 - src.models.model_promotion - INFO - Model meets quality threshold (6.9126 < 15.0000)
2025-12-10 16:25:08,055 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9126 < 15.0000)
2025-12-10 16:25:08,055 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_3 version 11
2025-12-10 16:25:08,150 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:08,245 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:08,339 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_3 v11
2025-12-10 16:25:08,339 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 3
2025-12-10 16:25:08,339 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 3, stage Production
üèÉ View run train_horizon_3_20251210_162504 at: http://host.docker.internal:5050/#/experiments/1/runs/84ba9b25bd8442498dce73349b9dd90b
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:08,441 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:08,441 - __main__ - INFO - Training Horizon 4 Days Ahead
2025-12-10 16:25:08,441 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:08,441 - __main__ - INFO - Starting run: train_horizon_4_20251210_162508
2025-12-10 16:25:08,491 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:08,491 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/0e1b424b49ef4ce98ae2ae260029d3ca/artifacts
2025-12-10 16:25:08,764 - src.models.train - INFO - Starting training for horizon 4 days
2025-12-10 16:25:08,764 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:08,764 - src.models.train - INFO - Creating shifted target for horizon=4 days
2025-12-10 16:25:08,766 - src.models.train - INFO - Created target for horizon 4: 1265 samples (4 rows removed due to shifting)
2025-12-10 16:25:08,766 - src.models.train - INFO - Data split: Train=759 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:25:08,767 - src.models.train - INFO - Features: 33
2025-12-10 16:25:08,767 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:08,768 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:08,768 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:08,892 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:08,894 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:08,894 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:08,919 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:08,921 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:08,921 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:08,992 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:08,994 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:08,994 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,045 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,048 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,048 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,095 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,097 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,097 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,229 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,232 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,232 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,353 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,355 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,355 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,426 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,428 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,429 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,557 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,560 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,560 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,580 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,582 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:09,582 - src.models.train - INFO - Best validation MAE: 6.6643
2025-12-10 16:25:09,582 - src.models.train - INFO - Best parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}
2025-12-10 16:25:09,582 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:09,582 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:25:09,582 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:25:09,603 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:25:09,603 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:09,603 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:09,603 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:09,632 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:09,632 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:25:09,635 - src.models.evaluation - INFO - Evaluation: MAE=6.80, RMSE=9.15, Coverage=96.5%, Width=36.36
2025-12-10 16:25:09,635 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:09,635 - src.models.train - INFO -   MAE: 6.7997
2025-12-10 16:25:09,635 - src.models.train - INFO -   RMSE: 9.1516
2025-12-10 16:25:09,635 - src.models.train - INFO -   Coverage: 96.46%
2025-12-10 16:25:09,635 - src.models.train - INFO -   Interval Width: 36.36
2025-12-10 16:25:09,635 - src.models.train - INFO - Training complete for horizon 4
2025-12-10 16:25:09,645 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:09,954 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6643, test_mae=6.7997, test_rmse=9.1516, test_coverage=0.9646, test_interval_width=36.3634
2025-12-10 16:25:09,954 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 4: MAE=6.80, RMSE=9.15
2025-12-10 16:25:09,954 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_4.pkl
2025-12-10 16:25:09,957 - src.models.lightgbm_model - INFO - Model saved successfully (193.5 KB)
2025-12-10 16:25:11,820 - __main__ - INFO - Model registered: er_forecast_horizon_4 v11
2025-12-10 16:25:11,820 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 4, stage Staging
2025-12-10 16:25:11,911 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:11,911 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:11,911 - src.models.model_promotion - INFO - Test MAE: 6.7997, Threshold: 15.0000
2025-12-10 16:25:11,911 - src.models.model_promotion - INFO - Model meets quality threshold (6.7997 < 15.0000)
2025-12-10 16:25:11,911 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.7997 < 15.0000)
2025-12-10 16:25:11,911 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_4 version 11
2025-12-10 16:25:12,002 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:12,093 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:12,184 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_4 v11
2025-12-10 16:25:12,184 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 4
2025-12-10 16:25:12,184 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 4, stage Production
üèÉ View run train_horizon_4_20251210_162508 at: http://host.docker.internal:5050/#/experiments/1/runs/0e1b424b49ef4ce98ae2ae260029d3ca
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:12,283 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:12,283 - __main__ - INFO - Training Horizon 5 Days Ahead
2025-12-10 16:25:12,283 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:12,283 - __main__ - INFO - Starting run: train_horizon_5_20251210_162512
2025-12-10 16:25:12,332 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:12,332 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/a23f588ed4ca48489a1f1a7ea2cfa798/artifacts
2025-12-10 16:25:12,599 - src.models.train - INFO - Starting training for horizon 5 days
2025-12-10 16:25:12,599 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:12,599 - src.models.train - INFO - Creating shifted target for horizon=5 days
2025-12-10 16:25:12,601 - src.models.train - INFO - Created target for horizon 5: 1264 samples (5 rows removed due to shifting)
2025-12-10 16:25:12,601 - src.models.train - INFO - Data split: Train=758 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:25:12,602 - src.models.train - INFO - Features: 33
2025-12-10 16:25:12,602 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:12,603 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,603 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:12,727 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:12,730 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,730 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:12,756 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:12,759 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,759 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:12,833 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:12,835 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,835 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:12,887 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:12,889 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,889 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:12,926 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:12,928 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:12,928 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,050 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,052 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:13,052 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,130 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,132 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:13,132 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,207 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,209 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:13,209 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,342 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,344 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:13,344 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,365 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,367 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:13,367 - src.models.train - INFO - Best validation MAE: 6.8729
2025-12-10 16:25:13,367 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:25:13,367 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:13,367 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:25:13,367 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:25:13,441 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:25:13,442 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:13,442 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:13,442 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:13,501 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:13,502 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:25:13,505 - src.models.evaluation - INFO - Evaluation: MAE=6.84, RMSE=9.23, Coverage=96.9%, Width=38.71
2025-12-10 16:25:13,505 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:13,505 - src.models.train - INFO -   MAE: 6.8373
2025-12-10 16:25:13,505 - src.models.train - INFO -   RMSE: 9.2277
2025-12-10 16:25:13,505 - src.models.train - INFO -   Coverage: 96.85%
2025-12-10 16:25:13,505 - src.models.train - INFO -   Interval Width: 38.71
2025-12-10 16:25:13,505 - src.models.train - INFO - Training complete for horizon 5
2025-12-10 16:25:13,515 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:13,830 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.8729, test_mae=6.8373, test_rmse=9.2277, test_coverage=0.9685, test_interval_width=38.7130
2025-12-10 16:25:13,830 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 5: MAE=6.84, RMSE=9.23
2025-12-10 16:25:13,830 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_5.pkl
2025-12-10 16:25:13,836 - src.models.lightgbm_model - INFO - Model saved successfully (531.5 KB)
2025-12-10 16:25:15,715 - __main__ - INFO - Model registered: er_forecast_horizon_5 v11
2025-12-10 16:25:15,715 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 5, stage Staging
2025-12-10 16:25:15,806 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:15,806 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:15,806 - src.models.model_promotion - INFO - Test MAE: 6.8373, Threshold: 15.0000
2025-12-10 16:25:15,806 - src.models.model_promotion - INFO - Model meets quality threshold (6.8373 < 15.0000)
2025-12-10 16:25:15,806 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.8373 < 15.0000)
2025-12-10 16:25:15,807 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_5 version 11
2025-12-10 16:25:15,897 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:15,988 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:16,079 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_5 v11
2025-12-10 16:25:16,079 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 5
2025-12-10 16:25:16,079 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 5, stage Production
üèÉ View run train_horizon_5_20251210_162512 at: http://host.docker.internal:5050/#/experiments/1/runs/a23f588ed4ca48489a1f1a7ea2cfa798
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:16,180 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:16,180 - __main__ - INFO - Training Horizon 6 Days Ahead
2025-12-10 16:25:16,180 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:16,180 - __main__ - INFO - Starting run: train_horizon_6_20251210_162516
2025-12-10 16:25:16,228 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:16,228 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/e9b093eacf4e4add884ae607b2de7498/artifacts
2025-12-10 16:25:16,498 - src.models.train - INFO - Starting training for horizon 6 days
2025-12-10 16:25:16,498 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:16,498 - src.models.train - INFO - Creating shifted target for horizon=6 days
2025-12-10 16:25:16,500 - src.models.train - INFO - Created target for horizon 6: 1263 samples (6 rows removed due to shifting)
2025-12-10 16:25:16,500 - src.models.train - INFO - Data split: Train=757 (59.9%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:25:16,501 - src.models.train - INFO - Features: 33
2025-12-10 16:25:16,501 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:16,502 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,502 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,629 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,631 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,631 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,658 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,660 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,660 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,733 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,735 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,735 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,788 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,790 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,790 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,829 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,831 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,831 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:16,953 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:16,956 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:16,956 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:17,032 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:17,034 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:17,034 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:17,105 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:17,107 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:17,107 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:17,243 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:17,245 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:17,245 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:17,267 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:17,268 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:17,268 - src.models.train - INFO - Best validation MAE: 6.8089
2025-12-10 16:25:17,268 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:25:17,268 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:17,268 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:25:17,268 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:25:17,341 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:17,341 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:17,341 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:17,341 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:17,406 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:17,406 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:25:17,409 - src.models.evaluation - INFO - Evaluation: MAE=6.63, RMSE=9.00, Coverage=96.9%, Width=38.64
2025-12-10 16:25:17,409 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:17,409 - src.models.train - INFO -   MAE: 6.6328
2025-12-10 16:25:17,409 - src.models.train - INFO -   RMSE: 8.9996
2025-12-10 16:25:17,409 - src.models.train - INFO -   Coverage: 96.85%
2025-12-10 16:25:17,409 - src.models.train - INFO -   Interval Width: 38.64
2025-12-10 16:25:17,409 - src.models.train - INFO - Training complete for horizon 6
2025-12-10 16:25:17,418 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:17,732 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.8089, test_mae=6.6328, test_rmse=8.9996, test_coverage=0.9685, test_interval_width=38.6386
2025-12-10 16:25:17,732 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 6: MAE=6.63, RMSE=9.00
2025-12-10 16:25:17,732 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_6.pkl
2025-12-10 16:25:17,738 - src.models.lightgbm_model - INFO - Model saved successfully (540.1 KB)
2025-12-10 16:25:19,615 - __main__ - INFO - Model registered: er_forecast_horizon_6 v11
2025-12-10 16:25:19,615 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 6, stage Staging
2025-12-10 16:25:19,706 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:19,706 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:19,706 - src.models.model_promotion - INFO - Test MAE: 6.6328, Threshold: 15.0000
2025-12-10 16:25:19,706 - src.models.model_promotion - INFO - Model meets quality threshold (6.6328 < 15.0000)
2025-12-10 16:25:19,706 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.6328 < 15.0000)
2025-12-10 16:25:19,706 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_6 version 11
2025-12-10 16:25:19,797 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:19,888 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:19,979 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_6 v11
2025-12-10 16:25:19,979 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 6
2025-12-10 16:25:19,979 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 6, stage Production
üèÉ View run train_horizon_6_20251210_162516 at: http://host.docker.internal:5050/#/experiments/1/runs/e9b093eacf4e4add884ae607b2de7498
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:20,081 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:20,081 - __main__ - INFO - Training Horizon 7 Days Ahead
2025-12-10 16:25:20,081 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:25:20,081 - __main__ - INFO - Starting run: train_horizon_7_20251210_162520
2025-12-10 16:25:20,130 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:25:20,130 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/16d352086ddc48068cb3955de15ab567/artifacts
2025-12-10 16:25:20,403 - src.models.train - INFO - Starting training for horizon 7 days
2025-12-10 16:25:20,403 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:25:20,403 - src.models.train - INFO - Creating shifted target for horizon=7 days
2025-12-10 16:25:20,405 - src.models.train - INFO - Created target for horizon 7: 1262 samples (7 rows removed due to shifting)
2025-12-10 16:25:20,405 - src.models.train - INFO - Data split: Train=757 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=253 (20.0%)
2025-12-10 16:25:20,406 - src.models.train - INFO - Features: 33
2025-12-10 16:25:20,406 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:25:20,407 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,407 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,533 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,536 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,536 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,560 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,562 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,562 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,632 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,635 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,635 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,687 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,689 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,689 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,728 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,730 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,730 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,854 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,856 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,856 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:20,929 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:20,931 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:20,931 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:21,002 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:21,005 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:21,005 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:21,129 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:21,131 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:21,131 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:21,152 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:21,154 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:25:21,154 - src.models.train - INFO - Best validation MAE: 6.4421
2025-12-10 16:25:21,154 - src.models.train - INFO - Best parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}
2025-12-10 16:25:21,154 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:25:21,154 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:25:21,154 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:25:21,278 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:25:21,278 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:25:21,278 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:25:21,278 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:25:21,304 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:25:21,304 - src.models.evaluation - INFO - Evaluating model on 253 test samples
2025-12-10 16:25:21,307 - src.models.evaluation - INFO - Evaluation: MAE=6.95, RMSE=9.26, Coverage=96.4%, Width=40.14
2025-12-10 16:25:21,308 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:25:21,308 - src.models.train - INFO -   MAE: 6.9527
2025-12-10 16:25:21,308 - src.models.train - INFO -   RMSE: 9.2642
2025-12-10 16:25:21,308 - src.models.train - INFO -   Coverage: 96.44%
2025-12-10 16:25:21,308 - src.models.train - INFO -   Interval Width: 40.14
2025-12-10 16:25:21,308 - src.models.train - INFO - Training complete for horizon 7
2025-12-10 16:25:21,316 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:25:21,619 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.4421, test_mae=6.9527, test_rmse=9.2642, test_coverage=0.9644, test_interval_width=40.1352
2025-12-10 16:25:21,619 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 7: MAE=6.95, RMSE=9.26
2025-12-10 16:25:21,619 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_7.pkl
2025-12-10 16:25:21,624 - src.models.lightgbm_model - INFO - Model saved successfully (522.6 KB)
2025-12-10 16:25:23,493 - __main__ - INFO - Model registered: er_forecast_horizon_7 v11
2025-12-10 16:25:23,493 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 7, stage Staging
2025-12-10 16:25:23,584 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 10)
2025-12-10 16:25:23,584 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:25:23,584 - src.models.model_promotion - INFO - Test MAE: 6.9527, Threshold: 15.0000
2025-12-10 16:25:23,584 - src.models.model_promotion - INFO - Model meets quality threshold (6.9527 < 15.0000)
2025-12-10 16:25:23,584 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9527 < 15.0000)
2025-12-10 16:25:23,584 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_7 version 11
2025-12-10 16:25:23,675 - src.models.model_promotion - INFO - Archiving existing production model: version 10
2025-12-10 16:25:23,766 - src.models.model_promotion - INFO - Version 10 archived
2025-12-10 16:25:23,857 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_7 v11
2025-12-10 16:25:23,857 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 7
2025-12-10 16:25:23,857 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 7, stage Production
üèÉ View run train_horizon_7_20251210_162520 at: http://host.docker.internal:5050/#/experiments/1/runs/16d352086ddc48068cb3955de15ab567
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:25:23,959 - __main__ - INFO - 
======================================================================
2025-12-10 16:25:23,959 - __main__ - INFO - STEP 6: Archiving Old Model Versions
2025-12-10 16:25:23,959 - __main__ - INFO - ======================================================================
2025-12-10 16:25:23,959 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_1
2025-12-10 16:25:23,959 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:23,972 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:23,972 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:23,972 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_2
2025-12-10 16:25:23,972 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:23,979 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:23,980 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:23,980 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_3
2025-12-10 16:25:23,980 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:23,986 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:23,986 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:23,986 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_4
2025-12-10 16:25:23,986 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:23,992 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:23,992 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:23,992 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_5
2025-12-10 16:25:23,992 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:23,998 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:23,998 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:23,999 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_6
2025-12-10 16:25:23,999 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:24,005 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:24,005 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:24,005 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_7
2025-12-10 16:25:24,005 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:25:24,011 - src.models.model_promotion - INFO - Found 11 total versions
2025-12-10 16:25:24,011 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:25:24,011 - __main__ - INFO - Archived 0 old model versions across all horizons
2025-12-10 16:25:24,011 - __main__ - INFO - 
======================================================================
2025-12-10 16:25:24,011 - __main__ - INFO - STEP 7: Creating Summary Report
2025-12-10 16:25:24,011 - __main__ - INFO - ======================================================================
2025-12-10 16:25:24,012 - __main__ - INFO - Training summary saved to: logs/training_summary_20251210_162524.md
2025-12-10 16:25:24,012 - __main__ - INFO - 
======================================================================
2025-12-10 16:25:24,012 - __main__ - INFO - TRAINING FLOW COMPLETE! 
2025-12-10 16:25:24,012 - __main__ - INFO - ======================================================================
2025-12-10 16:25:24,012 - src.monitoring.metrics_collector - INFO - Recorded flow run status: training_flow - success
2025-12-10 16:25:24,012 - __main__ - INFO - Training completed successfully: 7 models trained, 7 promoted

2025-12-10 16:25:24,413 [ERROR] Training STDERR:
time="2025-12-10T16:24:49Z" level=warning msg="Found orphan containers ([er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.67ms
2025/12/10 16:24:56 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet

[I 2025-12-10 16:24:56,433] A new study created in memory with name: no-name-a2caa68d-375f-442b-88b8-0b121a2d5bc1
[I 2025-12-10 16:24:56,563] Trial 0 finished with value: 6.512265283093906 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.512265283093906.
[I 2025-12-10 16:24:56,592] Trial 1 finished with value: 10.085492193040922 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.512265283093906.
[I 2025-12-10 16:24:56,668] Trial 2 finished with value: 6.505030047788321 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:56,722] Trial 3 finished with value: 6.86794718519191 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:56,763] Trial 4 finished with value: 6.666344221508085 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:56,885] Trial 5 finished with value: 7.292237453838007 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:56,961] Trial 6 finished with value: 6.834370750941091 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:57,034] Trial 7 finished with value: 6.878080904495041 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:57,170] Trial 8 finished with value: 8.290999070572832 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:24:57,193] Trial 9 finished with value: 6.633105855632679 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.505030047788321.
2025/12/10 16:24:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:24:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:24:59 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:24:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_1' already exists. Creating a new version of this model...
2025/12/10 16:24:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_1, version 11
Created version '11' of model 'er_forecast_horizon_1'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:00,927] A new study created in memory with name: no-name-a73def92-1451-414c-b770-d863c28d4c2e
[I 2025-12-10 16:25:01,058] Trial 0 finished with value: 6.782316802758262 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.782316802758262.
[I 2025-12-10 16:25:01,085] Trial 1 finished with value: 9.998013056291104 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.782316802758262.
[I 2025-12-10 16:25:01,156] Trial 2 finished with value: 6.648412014759784 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,209] Trial 3 finished with value: 7.563951983408843 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,249] Trial 4 finished with value: 7.5330410276384825 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,381] Trial 5 finished with value: 7.547934169796517 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,455] Trial 6 finished with value: 6.82705517668433 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,528] Trial 7 finished with value: 7.4158195121780714 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,660] Trial 8 finished with value: 8.108724772794112 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:25:01,684] Trial 9 finished with value: 6.722453796244694 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.648412014759784.
2025/12/10 16:25:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:02 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:03 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_2' already exists. Creating a new version of this model...
2025/12/10 16:25:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_2, version 11
Created version '11' of model 'er_forecast_horizon_2'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:04,845] A new study created in memory with name: no-name-59488245-c93d-4a71-8bf5-c27040059eba
[I 2025-12-10 16:25:04,977] Trial 0 finished with value: 7.0457087833301895 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 7.0457087833301895.
[I 2025-12-10 16:25:05,007] Trial 1 finished with value: 10.014195910665732 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 7.0457087833301895.
[I 2025-12-10 16:25:05,083] Trial 2 finished with value: 6.648803536132593 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,137] Trial 3 finished with value: 7.904063453959654 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,180] Trial 4 finished with value: 7.499845018525743 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,307] Trial 5 finished with value: 7.721197567347179 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,386] Trial 6 finished with value: 6.941374383645906 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,459] Trial 7 finished with value: 7.318939231628028 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,589] Trial 8 finished with value: 8.179073537322086 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:25:05,612] Trial 9 finished with value: 6.767924424639475 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.648803536132593.
2025/12/10 16:25:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:06 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:07 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_3' already exists. Creating a new version of this model...
2025/12/10 16:25:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_3, version 11
Created version '11' of model 'er_forecast_horizon_3'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:08,767] A new study created in memory with name: no-name-1e3eda62-3807-470f-8ad9-705d28571e31
[I 2025-12-10 16:25:08,893] Trial 0 finished with value: 6.891976215905066 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.891976215905066.
[I 2025-12-10 16:25:08,920] Trial 1 finished with value: 10.07568987588107 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.891976215905066.
[I 2025-12-10 16:25:08,994] Trial 2 finished with value: 6.714104392351724 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,047] Trial 3 finished with value: 6.913568773375855 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,096] Trial 4 finished with value: 6.871145871991883 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,231] Trial 5 finished with value: 6.9798221446676 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,354] Trial 6 finished with value: 6.919413472587999 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,428] Trial 7 finished with value: 6.8440033976624255 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,559] Trial 8 finished with value: 8.238547699839744 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:25:09,582] Trial 9 finished with value: 6.66429078792307 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 9 with value: 6.66429078792307.
2025/12/10 16:25:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:10 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_4' already exists. Creating a new version of this model...
2025/12/10 16:25:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_4, version 11
Created version '11' of model 'er_forecast_horizon_4'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:12,602] A new study created in memory with name: no-name-8e062781-3864-43c8-8166-1c7ae9f3c31d
[I 2025-12-10 16:25:12,729] Trial 0 finished with value: 7.16259264805606 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 7.16259264805606.
[I 2025-12-10 16:25:12,758] Trial 1 finished with value: 10.104027523554073 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 7.16259264805606.
[I 2025-12-10 16:25:12,835] Trial 2 finished with value: 6.872930172388908 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:12,888] Trial 3 finished with value: 7.34826692491851 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:12,928] Trial 4 finished with value: 7.349687825358949 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:13,051] Trial 5 finished with value: 7.642954778066336 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:13,132] Trial 6 finished with value: 7.071456341505532 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:13,208] Trial 7 finished with value: 7.494545305669174 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:13,343] Trial 8 finished with value: 8.276343580428234 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:25:13,367] Trial 9 finished with value: 6.999303650518748 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.872930172388908.
2025/12/10 16:25:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:15 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_5' already exists. Creating a new version of this model...
2025/12/10 16:25:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_5, version 11
Created version '11' of model 'er_forecast_horizon_5'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:16,502] A new study created in memory with name: no-name-c7946c25-25a7-409e-87f6-70794b3e6882
[I 2025-12-10 16:25:16,630] Trial 0 finished with value: 6.997173869266218 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.997173869266218.
[I 2025-12-10 16:25:16,659] Trial 1 finished with value: 10.133613571261762 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.997173869266218.
[I 2025-12-10 16:25:16,735] Trial 2 finished with value: 6.808851332471394 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:16,789] Trial 3 finished with value: 7.37353060303102 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:16,830] Trial 4 finished with value: 7.191029665851202 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:16,955] Trial 5 finished with value: 7.731251202584651 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:17,033] Trial 6 finished with value: 7.121457728899293 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:17,106] Trial 7 finished with value: 7.56536537483717 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:17,244] Trial 8 finished with value: 8.400166033962144 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:25:17,268] Trial 9 finished with value: 6.87010953323339 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.808851332471394.
2025/12/10 16:25:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:18 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_6' already exists. Creating a new version of this model...
2025/12/10 16:25:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_6, version 11
Created version '11' of model 'er_forecast_horizon_6'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:25:20,406] A new study created in memory with name: no-name-66e09f53-40f4-4473-8a88-b44919cf4668
[I 2025-12-10 16:25:20,535] Trial 0 finished with value: 6.4420807748022 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,562] Trial 1 finished with value: 9.90331073321374 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,634] Trial 2 finished with value: 6.565271871839189 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,689] Trial 3 finished with value: 7.252551914513719 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,729] Trial 4 finished with value: 6.711293044129217 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,855] Trial 5 finished with value: 6.990633290417701 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:20,930] Trial 6 finished with value: 6.70430998070908 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:21,004] Trial 7 finished with value: 6.836893448002367 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:21,130] Trial 8 finished with value: 8.051646297117072 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:25:21,153] Trial 9 finished with value: 6.510827182108662 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 0 with value: 6.4420807748022.
2025/12/10 16:25:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:25:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:25:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:25:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_7' already exists. Creating a new version of this model...
2025/12/10 16:25:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_7, version 11
Created version '11' of model 'er_forecast_horizon_7'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(

2025-12-10 16:25:24,413 [INFO] Training completed successfully
2025-12-10 16:25:24,413 [INFO] 10.30.53.44 - - [10/Dec/2025 16:25:24] "GET /train HTTP/1.1" 200 -
2025-12-10 16:27:31,722 [INFO] 10.30.53.44 - - [10/Dec/2025 16:27:31] "[33mGET /training HTTP/1.1[0m" 404 -
2025-12-10 16:27:33,950 [INFO] Received /predict request
2025-12-10 16:27:44,555 [INFO] Prediction STDOUT:
2025-12-10 16:27:38,704 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-10 16:27:38,704 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-10 16:27:38,704 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-10 16:27:38,704 - __main__ - INFO - ======================================================================
2025-12-10 16:27:38,704 - __main__ - INFO - STARTING ER PATIENT FORECAST PREDICTION FLOW
2025-12-10 16:27:38,704 - __main__ - INFO - ======================================================================
2025-12-10 16:27:38,704 - __main__ - INFO - Prediction base date: 2025-12-10
2025-12-10 16:27:38,705 - __main__ - INFO - Output path: data/predictions/
2025-12-10 16:27:38,705 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:38,705 - __main__ - INFO - STEP 1: Loading Latest Patient Data
2025-12-10 16:27:38,705 - __main__ - INFO - ======================================================================
2025-12-10 16:27:38,705 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-10 16:27:38,705 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-10 16:27:40,429 - src.data.preprocessing - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:27:40,464 - __main__ - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:27:40,464 - src.data.preprocessing - INFO - Removing duplicates from 277,534 rows
2025-12-10 16:27:40,485 - src.data.preprocessing - WARNING - Found 200,196 duplicate rows (72.13%)
2025-12-10 16:27:40,488 - src.data.preprocessing - INFO - After removing duplicates: 77,338 rows remain
2025-12-10 16:27:40,491 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-10 16:27:40,555 - src.data.preprocessing - INFO - Aggregated to 1,287 days
2025-12-10 16:27:40,555 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-10 00:00:00
2025-12-10 16:27:40,555 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-10 16:27:40,555 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-10 16:27:40,555 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-10 16:27:40,558 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-10 16:27:40,559 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-10 16:27:40,562 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-10 16:27:40,563 - src.data.preprocessing - INFO - Final time series: 1,297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:27:40,563 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-10 16:27:40,564 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-10 16:27:40,564 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-10 16:27:40,564 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-10 16:27:40,564 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-10 16:27:40,564 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-10 16:27:40,565 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-10 16:27:40,565 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-10 16:27:40,565 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-10 16:27:40,565 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-10 16:27:40,566 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-10 16:27:40,566 - __main__ - INFO - Loaded data: 1297 days up to 2025-12-10
2025-12-10 16:27:40,566 - __main__ - INFO - Data validation passed: 1297 rows, most recent date 2025-12-10 (0 days ago)
2025-12-10 16:27:40,566 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:40,566 - __main__ - INFO - STEP 2: Fetching Weather Data (Historical + Forecast)
2025-12-10 16:27:40,566 - __main__ - INFO - ======================================================================
2025-12-10 16:27:40,566 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-10
2025-12-10 16:27:40,566 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:27:40,767 - src.data.weather_integration - INFO - Successfully fetched weather data: 1297 days
2025-12-10 16:27:40,768 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-10 16:27:40,770 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-10
2025-12-10 16:27:40,770 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-10
2025-12-10 16:27:40,771 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-10 16:27:40,771 - __main__ - INFO - Historical weather data: 1297 days
2025-12-10 16:27:40,771 - src.data.weather_integration - INFO - Fetching weather forecast for next 8 days
2025-12-10 16:27:40,771 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:27:40,897 - src.data.weather_integration - INFO - Successfully fetched weather forecast: 8 days
2025-12-10 16:27:40,897 - __main__ - INFO - Weather forecast fetched: 8 days
2025-12-10 16:27:40,897 - __main__ - INFO - Forecast date range: 2025-12-10 to 2025-12-17
2025-12-10 16:27:40,897 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:40,898 - __main__ - INFO - STEP 3: Engineering Features
2025-12-10 16:27:40,898 - __main__ - INFO - ======================================================================
2025-12-10 16:27:40,898 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-10 16:27:40,898 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-10 16:27:40,901 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-10 16:27:40,901 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-10 16:27:40,902 - src.data.feature_engineering - INFO - Weekend days: 370/1297 (28.5%)
2025-12-10 16:27:40,902 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-10 16:27:40,903 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-10 16:27:40,904 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Adding change features
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Added change features
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Final shape: (1297, 35)
2025-12-10 16:27:40,905 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-10 16:27:40,906 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-10 16:27:40,906 - src.data.feature_engineering - INFO - Rows with NaN: 28/1297 (2.2%)
2025-12-10 16:27:40,907 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-10 16:27:40,907 - src.data.feature_engineering - INFO - Remaining rows: 1269
2025-12-10 16:27:40,907 - __main__ - INFO - Features engineered: (1269, 35)
2025-12-10 16:27:40,907 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:40,907 - __main__ - INFO - STEP 4: Loading Production Models from MLflow
2025-12-10 16:27:40,907 - __main__ - INFO - ======================================================================
2025-12-10 16:27:40,907 - src.models.predict - INFO - Loading production models from MLflow Model Registry
2025-12-10 16:27:40,907 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_1
2025-12-10 16:27:41,296 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:41,612 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-10 16:27:41,733 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:27:41,733 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_1 v11
2025-12-10 16:27:41,733 - src.models.predict - INFO - Loaded model for horizon 1
2025-12-10 16:27:41,733 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_2
2025-12-10 16:27:41,785 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:41,950 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:27:41,950 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_2 v11
2025-12-10 16:27:41,950 - src.models.predict - INFO - Loaded model for horizon 2
2025-12-10 16:27:41,950 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_3
2025-12-10 16:27:42,043 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:42,209 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:27:42,210 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_3 v11
2025-12-10 16:27:42,210 - src.models.predict - INFO - Loaded model for horizon 3
2025-12-10 16:27:42,210 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_4
2025-12-10 16:27:42,303 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:42,468 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:27:42,468 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_4 v11
2025-12-10 16:27:42,468 - src.models.predict - INFO - Loaded model for horizon 4
2025-12-10 16:27:42,468 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_5
2025-12-10 16:27:42,560 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:42,724 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:27:42,724 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_5 v11
2025-12-10 16:27:42,724 - src.models.predict - INFO - Loaded model for horizon 5
2025-12-10 16:27:42,724 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_6
2025-12-10 16:27:42,817 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:42,984 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:27:42,984 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_6 v11
2025-12-10 16:27:42,984 - src.models.predict - INFO - Loaded model for horizon 6
2025-12-10 16:27:42,984 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_7
2025-12-10 16:27:43,077 - src.utils.mlflow_utils - INFO - Loading model version 11 from Production stage
2025-12-10 16:27:43,242 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:27:43,242 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_7 v11
2025-12-10 16:27:43,242 - src.models.predict - INFO - Loaded model for horizon 7
2025-12-10 16:27:43,242 - src.models.predict - INFO - Successfully loaded all 7 production models from MLflow
2025-12-10 16:27:43,242 - __main__ - INFO - Loaded 7 production models
2025-12-10 16:27:43,242 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:43,242 - __main__ - INFO - STEP 5: Preparing Prediction Features
2025-12-10 16:27:43,242 - __main__ - INFO - ======================================================================
2025-12-10 16:27:43,242 - src.models.predict - INFO - Preparing features for prediction
2025-12-10 16:27:43,242 - src.models.predict - INFO - Base date for predictions: 2025-12-10
2025-12-10 16:27:43,250 - src.models.predict - INFO - Prepared features for 7 prediction days
2025-12-10 16:27:43,250 - src.models.predict - INFO - Prediction date range: 2025-12-11 to 2025-12-17
2025-12-10 16:27:43,250 - src.models.predict - INFO - Weather forecasts applied to prediction features
2025-12-10 16:27:43,250 - src.models.predict - INFO - Total columns in prediction features: 35
2025-12-10 16:27:43,250 - __main__ - INFO - Features prepared for next 7 days
2025-12-10 16:27:43,250 - __main__ - INFO - Each horizon has weather forecast for its target date
2025-12-10 16:27:43,250 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:43,250 - __main__ - INFO - STEP 6: Generating Predictions with Confidence Intervals
2025-12-10 16:27:43,250 - __main__ - INFO - ======================================================================
2025-12-10 16:27:43,250 - src.models.predict - INFO - Generating batch predictions for next 7 days
2025-12-10 16:27:43,250 - src.models.predict - INFO - Feature columns selected: 33 features
2025-12-10 16:27:43,270 - src.models.predict - INFO - Generated 7 predictions
2025-12-10 16:27:43,271 - src.models.predict - INFO - Prediction range: 51.6 to 70.9 patients
2025-12-10 16:27:43,272 - src.monitoring.metrics_collector - INFO - Recorded prediction metrics: 7 predictions in 0.02s
2025-12-10 16:27:43,272 - __main__ - INFO - Generated 7 predictions in 0.02s
2025-12-10 16:27:43,272 - __main__ - INFO -    Prediction range: 51.6 to 70.9 patients
2025-12-10 16:27:43,272 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:43,272 - __main__ - INFO - STEP 7: Saving Predictions
2025-12-10 16:27:43,272 - __main__ - INFO - ======================================================================
2025-12-10 16:27:43,272 - src.models.prediction_output - INFO - Saving predictions to CSV
2025-12-10 16:27:43,275 - src.models.prediction_output - INFO - Predictions saved to: data/predictions/predictions_20251210_162743.csv
2025-12-10 16:27:43,275 - src.models.prediction_output - INFO - File size: 0.8 KB, Rows: 7
2025-12-10 16:27:43,275 - __main__ - INFO - Predictions saved to CSV: data/predictions/predictions_20251210_162743.csv
2025-12-10 16:27:43,275 - src.models.prediction_output - INFO - Writing predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:27:43,299 - src.models.prediction_output - INFO - Successfully wrote 7 predictions to [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:27:43,299 - __main__ - INFO - Wrote 7 predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:27:43,299 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:43,299 - __main__ - INFO - STEP 8: Logging Metadata to MLflow
2025-12-10 16:27:43,299 - __main__ - INFO - ======================================================================
2025-12-10 16:27:43,299 - src.models.prediction_output - INFO - Logging prediction metadata to MLflow
2025-12-10 16:27:44,108 - src.models.prediction_output - INFO - Prediction metadata logged to MLflow run: 0be96d470e604507b44855caf145bcd8
üèÉ View run batch_prediction_2025-12-10_16:27:43 at: http://host.docker.internal:5050/#/experiments/2/runs/0be96d470e604507b44855caf145bcd8
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/2
2025-12-10 16:27:44,164 - __main__ - INFO - Logged to MLflow run: 0be96d470e604507b44855caf145bcd8
2025-12-10 16:27:44,165 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:44,165 - __main__ - INFO - PREDICTION FLOW COMPLETE! 
2025-12-10 16:27:44,165 - __main__ - INFO - ======================================================================
2025-12-10 16:27:44,165 - __main__ - INFO - Average prediction: 63.1 patients
2025-12-10 16:27:44,165 - __main__ - INFO - Average interval width: 37.507799975995844
2025-12-10 16:27:44,165 - src.monitoring.metrics_collector - INFO - Recorded flow run status: prediction_flow - success
2025-12-10 16:27:44,167 - __main__ - INFO - Prediction completed successfully: 7 predictions

2025-12-10 16:27:44,556 [ERROR] Prediction STDERR:
time="2025-12-10T16:27:34Z" level=warning msg="Found orphan containers ([er-forecast-training-run-4766d86e3dc8 er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.58ms
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 24966.10it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 23109.11it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 24385.49it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 26092.09it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 8412.16it/s] 
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 6983.52it/s]
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 25420.02it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 22982.49it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 736.23it/s]  
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 702.86it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 703.84it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 694.74it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 209.46it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 293.63it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 209.28it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 270.64it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 320.02it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 318.18it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 181.39it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 331.71it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 225.76it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 272.91it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 334.11it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 332.18it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 32263.88it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 278.28it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 342.94it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 453.82it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 513.13it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 509.92it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 66.32it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 121.76it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 174.41it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 215.05it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 253.18it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 251.84it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 162.93it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 287.50it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 232.11it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 281.34it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 346.05it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 344.02it/s]
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
2025/12/10 16:27:43 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet


2025-12-10 16:27:44,556 [INFO] Prediction completed successfully
2025-12-10 16:27:44,556 [INFO] 10.30.53.44 - - [10/Dec/2025 16:27:44] "GET /predict HTTP/1.1" 200 -
2025-12-10 16:27:53,759 [INFO] Received /train request
2025-12-10 16:28:29,231 [INFO] Training STDOUT:
2025-12-10 16:27:58,681 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-10 16:27:58,681 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-10 16:27:58,681 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-10 16:27:58,681 - __main__ - INFO - ======================================================================
2025-12-10 16:27:58,681 - __main__ - INFO - STARTING ER PATIENT FORECAST TRAINING FLOW
2025-12-10 16:27:58,681 - __main__ - INFO - ======================================================================
2025-12-10 16:27:58,681 - __main__ - INFO - Raw data path: data/raw/emergency_visits.csv
2025-12-10 16:27:58,681 - __main__ - INFO - Horizons to train: [1, 2, 3, 4, 5, 6, 7]
2025-12-10 16:27:58,681 - __main__ - INFO - Optuna trials per horizon: 10
2025-12-10 16:27:58,681 - __main__ - INFO - MAE threshold for promotion: 15.0
2025-12-10 16:27:58,681 - __main__ - INFO - 
======================================================================
2025-12-10 16:27:58,681 - __main__ - INFO - STEP 1: Loading and Preprocessing Patient Data
2025-12-10 16:27:58,681 - __main__ - INFO - ======================================================================
2025-12-10 16:27:58,681 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-10 16:27:58,682 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-10 16:28:00,360 - src.data.preprocessing - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:28:00,398 - __main__ - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:28:00,398 - src.data.preprocessing - INFO - Removing duplicates from 277,534 rows
2025-12-10 16:28:00,417 - src.data.preprocessing - WARNING - Found 200,196 duplicate rows (72.13%)
2025-12-10 16:28:00,420 - src.data.preprocessing - INFO - After removing duplicates: 77,338 rows remain
2025-12-10 16:28:00,423 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-10 16:28:00,490 - src.data.preprocessing - INFO - Aggregated to 1,287 days
2025-12-10 16:28:00,490 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-10 00:00:00
2025-12-10 16:28:00,490 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-10 16:28:00,490 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-10 16:28:00,490 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-10 16:28:00,493 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-10 16:28:00,494 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-10 16:28:00,498 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-10 16:28:00,498 - src.data.preprocessing - INFO - Final time series: 1,297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:28:00,498 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-10 16:28:00,499 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-10 16:28:00,499 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-10 16:28:00,499 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-10 16:28:00,499 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-10 16:28:00,499 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-10 16:28:00,500 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-10 16:28:00,500 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-10 16:28:00,500 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-10 16:28:00,500 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-10 16:28:00,501 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-10 16:28:00,501 - __main__ - INFO - Preprocessed data: 1297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:28:00,501 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:00,501 - __main__ - INFO - STEP 2: Fetching Weather Data
2025-12-10 16:28:00,501 - __main__ - INFO - ======================================================================
2025-12-10 16:28:00,501 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-10
2025-12-10 16:28:00,501 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:28:00,660 - src.data.weather_integration - INFO - Successfully fetched weather data: 1297 days
2025-12-10 16:28:00,661 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-10 16:28:00,663 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-10
2025-12-10 16:28:00,663 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-10
2025-12-10 16:28:00,664 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-10 16:28:00,664 - __main__ - INFO - Weather data merged: 1297 days of weather
2025-12-10 16:28:00,664 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:00,664 - __main__ - INFO - STEP 3: Engineering Features
2025-12-10 16:28:00,664 - __main__ - INFO - ======================================================================
2025-12-10 16:28:00,664 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-10 16:28:00,664 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-10 16:28:00,667 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-10 16:28:00,668 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-10 16:28:00,669 - src.data.feature_engineering - INFO - Weekend days: 370/1297 (28.5%)
2025-12-10 16:28:00,669 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-10 16:28:00,670 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-10 16:28:00,670 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-10 16:28:00,671 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-10 16:28:00,671 - src.data.feature_engineering - INFO - Adding change features
2025-12-10 16:28:00,672 - src.data.feature_engineering - INFO - Added change features
2025-12-10 16:28:00,672 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-10 16:28:00,672 - src.data.feature_engineering - INFO - Final shape: (1297, 35)
2025-12-10 16:28:00,672 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-10 16:28:00,672 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-10 16:28:00,673 - src.data.feature_engineering - INFO - Rows with NaN: 28/1297 (2.2%)
2025-12-10 16:28:00,673 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-10 16:28:00,673 - src.data.feature_engineering - INFO - Remaining rows: 1269
2025-12-10 16:28:00,673 - __main__ - INFO - Feature engineering complete: 33 features, 1269 samples
2025-12-10 16:28:00,674 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:00,674 - __main__ - INFO - STEP 4: Training Models for All Horizons
2025-12-10 16:28:00,674 - __main__ - INFO - ======================================================================
2025-12-10 16:28:00,674 - src.utils.mlflow_utils - INFO - Setting MLflow experiment: ER_Patient_Forecasting_MinIO
2025-12-10 16:28:00,686 - src.utils.mlflow_utils - INFO - Using experiment: ER_Patient_Forecasting_MinIO (ID: 1)
2025-12-10 16:28:00,686 - __main__ - INFO - Set experiment to: ER_Patient_Forecasting_MinIO (ID: 1)
2025-12-10 16:28:00,731 - __main__ - INFO - Current experiment artifact location: s3://mlflow-artifacts/1
2025-12-10 16:28:00,731 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:00,731 - __main__ - INFO - Training Horizon 1 Days Ahead
2025-12-10 16:28:00,731 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:00,731 - __main__ - INFO - Starting run: train_horizon_1_20251210_162800
2025-12-10 16:28:00,824 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:00,824 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/6447f409c97f4884ad3ff14089e0c2b3/artifacts
2025-12-10 16:28:01,097 - src.models.train - INFO - Starting training for horizon 1 days
2025-12-10 16:28:01,097 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:01,097 - src.models.train - INFO - Creating shifted target for horizon=1 days
2025-12-10 16:28:01,099 - src.models.train - INFO - Created target for horizon 1: 1268 samples (1 rows removed due to shifting)
2025-12-10 16:28:01,099 - src.models.train - INFO - Data split: Train=760 (59.9%), Val=126 (9.9%), Calib=126 (9.9%), Test=256 (20.2%)
2025-12-10 16:28:01,100 - src.models.train - INFO - Features: 33
2025-12-10 16:28:01,100 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:01,101 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,101 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,289 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,292 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,292 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,320 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,322 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,322 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,399 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,401 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,401 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,453 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,455 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,456 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,496 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,498 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,498 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,622 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,624 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,624 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,700 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,703 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,703 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,775 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,777 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,777 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,916 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,918 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,918 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:01,940 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:01,941 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:01,941 - src.models.train - INFO - Best validation MAE: 6.5050
2025-12-10 16:28:01,942 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:28:01,942 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:01,942 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:28:01,942 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=1)
2025-12-10 16:28:02,018 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:02,018 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:02,018 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:02,018 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:02,084 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:02,084 - src.models.evaluation - INFO - Evaluating model on 256 test samples
2025-12-10 16:28:02,087 - src.models.evaluation - INFO - Evaluation: MAE=7.12, RMSE=9.54, Coverage=96.9%, Width=39.75
2025-12-10 16:28:02,087 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:02,087 - src.models.train - INFO -   MAE: 7.1188
2025-12-10 16:28:02,087 - src.models.train - INFO -   RMSE: 9.5393
2025-12-10 16:28:02,087 - src.models.train - INFO -   Coverage: 96.88%
2025-12-10 16:28:02,087 - src.models.train - INFO -   Interval Width: 39.75
2025-12-10 16:28:02,087 - src.models.train - INFO - Training complete for horizon 1
2025-12-10 16:28:02,097 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:02,403 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.5050, test_mae=7.1188, test_rmse=9.5393, test_coverage=0.9688, test_interval_width=39.7505
2025-12-10 16:28:02,403 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 1: MAE=7.12, RMSE=9.54
2025-12-10 16:28:02,404 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_1.pkl
2025-12-10 16:28:02,410 - src.models.lightgbm_model - INFO - Model saved successfully (556.0 KB)
2025-12-10 16:28:04,401 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-10 16:28:04,829 - __main__ - INFO - Model registered: er_forecast_horizon_1 v12
2025-12-10 16:28:04,829 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 1, stage Staging
2025-12-10 16:28:04,924 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:04,924 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:04,924 - src.models.model_promotion - INFO - Test MAE: 7.1188, Threshold: 15.0000
2025-12-10 16:28:04,924 - src.models.model_promotion - INFO - Model meets quality threshold (7.1188 < 15.0000)
2025-12-10 16:28:04,924 - __main__ - INFO - [PROMOTE] Model to production (MAE: 7.1188 < 15.0000)
2025-12-10 16:28:04,925 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_1 version 12
2025-12-10 16:28:05,019 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:05,115 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:05,271 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_1 v12
2025-12-10 16:28:05,271 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 1
2025-12-10 16:28:05,271 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 1, stage Production
üèÉ View run train_horizon_1_20251210_162800 at: http://host.docker.internal:5050/#/experiments/1/runs/6447f409c97f4884ad3ff14089e0c2b3
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:05,371 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:05,371 - __main__ - INFO - Training Horizon 2 Days Ahead
2025-12-10 16:28:05,371 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:05,371 - __main__ - INFO - Starting run: train_horizon_2_20251210_162805
2025-12-10 16:28:05,420 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:05,420 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/39a06e716f1d4442adc978e4e0a56c12/artifacts
2025-12-10 16:28:05,689 - src.models.train - INFO - Starting training for horizon 2 days
2025-12-10 16:28:05,689 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:05,689 - src.models.train - INFO - Creating shifted target for horizon=2 days
2025-12-10 16:28:05,691 - src.models.train - INFO - Created target for horizon 2: 1267 samples (2 rows removed due to shifting)
2025-12-10 16:28:05,691 - src.models.train - INFO - Data split: Train=760 (60.0%), Val=126 (9.9%), Calib=126 (9.9%), Test=255 (20.1%)
2025-12-10 16:28:05,692 - src.models.train - INFO - Features: 33
2025-12-10 16:28:05,692 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:05,693 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:05,693 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:05,825 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:05,827 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:05,827 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:05,855 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:05,857 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:05,857 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:05,930 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:05,932 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:05,932 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:05,986 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:05,988 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:05,988 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,028 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,031 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,031 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,159 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,161 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,161 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,236 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,238 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,238 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,323 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,330 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,330 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,499 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,501 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,502 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,524 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,525 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:06,525 - src.models.train - INFO - Best validation MAE: 6.6484
2025-12-10 16:28:06,525 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:28:06,525 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:06,525 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:28:06,526 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=2)
2025-12-10 16:28:06,595 - src.models.lightgbm_model - INFO - Point model trained with 760 samples
2025-12-10 16:28:06,595 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:06,595 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:06,595 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:06,670 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:06,670 - src.models.evaluation - INFO - Evaluating model on 255 test samples
2025-12-10 16:28:06,674 - src.models.evaluation - INFO - Evaluation: MAE=6.98, RMSE=9.54, Coverage=95.3%, Width=35.37
2025-12-10 16:28:06,674 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:06,674 - src.models.train - INFO -   MAE: 6.9791
2025-12-10 16:28:06,674 - src.models.train - INFO -   RMSE: 9.5413
2025-12-10 16:28:06,674 - src.models.train - INFO -   Coverage: 95.29%
2025-12-10 16:28:06,674 - src.models.train - INFO -   Interval Width: 35.37
2025-12-10 16:28:06,674 - src.models.train - INFO - Training complete for horizon 2
2025-12-10 16:28:06,682 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:06,972 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6484, test_mae=6.9791, test_rmse=9.5413, test_coverage=0.9529, test_interval_width=35.3670
2025-12-10 16:28:06,972 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 2: MAE=6.98, RMSE=9.54
2025-12-10 16:28:06,973 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_2.pkl
2025-12-10 16:28:06,978 - src.models.lightgbm_model - INFO - Model saved successfully (579.5 KB)
2025-12-10 16:28:08,851 - __main__ - INFO - Model registered: er_forecast_horizon_2 v12
2025-12-10 16:28:08,851 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 2, stage Staging
2025-12-10 16:28:08,946 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:08,946 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:08,946 - src.models.model_promotion - INFO - Test MAE: 6.9791, Threshold: 15.0000
2025-12-10 16:28:08,946 - src.models.model_promotion - INFO - Model meets quality threshold (6.9791 < 15.0000)
2025-12-10 16:28:08,946 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9791 < 15.0000)
2025-12-10 16:28:08,946 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_2 version 12
2025-12-10 16:28:09,041 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:09,136 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:09,230 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_2 v12
2025-12-10 16:28:09,230 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 2
2025-12-10 16:28:09,230 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 2, stage Production
üèÉ View run train_horizon_2_20251210_162805 at: http://host.docker.internal:5050/#/experiments/1/runs/39a06e716f1d4442adc978e4e0a56c12
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:09,330 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:09,330 - __main__ - INFO - Training Horizon 3 Days Ahead
2025-12-10 16:28:09,330 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:09,330 - __main__ - INFO - Starting run: train_horizon_3_20251210_162809
2025-12-10 16:28:09,379 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:09,379 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/b498538e02cb4a39b51df27b90708560/artifacts
2025-12-10 16:28:09,647 - src.models.train - INFO - Starting training for horizon 3 days
2025-12-10 16:28:09,647 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:09,647 - src.models.train - INFO - Creating shifted target for horizon=3 days
2025-12-10 16:28:09,649 - src.models.train - INFO - Created target for horizon 3: 1266 samples (3 rows removed due to shifting)
2025-12-10 16:28:09,649 - src.models.train - INFO - Data split: Train=759 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=255 (20.1%)
2025-12-10 16:28:09,650 - src.models.train - INFO - Features: 33
2025-12-10 16:28:09,650 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:09,651 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,651 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:09,778 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:09,781 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,781 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:09,807 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:09,809 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,810 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:09,882 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:09,884 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,885 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:09,937 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:09,939 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,939 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:09,979 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:09,981 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:09,981 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,105 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,107 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:10,107 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,182 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,185 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:10,185 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,256 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,258 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:10,258 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,384 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,387 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:10,387 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,408 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,410 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:10,410 - src.models.train - INFO - Best validation MAE: 6.6488
2025-12-10 16:28:10,410 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:28:10,410 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:10,410 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:28:10,410 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=3)
2025-12-10 16:28:10,482 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:10,482 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:10,482 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:10,482 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:10,545 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:10,545 - src.models.evaluation - INFO - Evaluating model on 255 test samples
2025-12-10 16:28:10,549 - src.models.evaluation - INFO - Evaluation: MAE=6.91, RMSE=9.52, Coverage=96.5%, Width=38.89
2025-12-10 16:28:10,549 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:10,549 - src.models.train - INFO -   MAE: 6.9126
2025-12-10 16:28:10,549 - src.models.train - INFO -   RMSE: 9.5154
2025-12-10 16:28:10,549 - src.models.train - INFO -   Coverage: 96.47%
2025-12-10 16:28:10,549 - src.models.train - INFO -   Interval Width: 38.89
2025-12-10 16:28:10,549 - src.models.train - INFO - Training complete for horizon 3
2025-12-10 16:28:10,556 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:10,852 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6488, test_mae=6.9126, test_rmse=9.5154, test_coverage=0.9647, test_interval_width=38.8899
2025-12-10 16:28:10,852 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 3: MAE=6.91, RMSE=9.52
2025-12-10 16:28:10,853 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_3.pkl
2025-12-10 16:28:10,858 - src.models.lightgbm_model - INFO - Model saved successfully (550.1 KB)
2025-12-10 16:28:12,744 - __main__ - INFO - Model registered: er_forecast_horizon_3 v12
2025-12-10 16:28:12,744 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 3, stage Staging
2025-12-10 16:28:12,840 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:12,840 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:12,840 - src.models.model_promotion - INFO - Test MAE: 6.9126, Threshold: 15.0000
2025-12-10 16:28:12,840 - src.models.model_promotion - INFO - Model meets quality threshold (6.9126 < 15.0000)
2025-12-10 16:28:12,840 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9126 < 15.0000)
2025-12-10 16:28:12,840 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_3 version 12
2025-12-10 16:28:12,935 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:13,030 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:13,124 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_3 v12
2025-12-10 16:28:13,124 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 3
2025-12-10 16:28:13,124 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 3, stage Production
üèÉ View run train_horizon_3_20251210_162809 at: http://host.docker.internal:5050/#/experiments/1/runs/b498538e02cb4a39b51df27b90708560
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:13,226 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:13,226 - __main__ - INFO - Training Horizon 4 Days Ahead
2025-12-10 16:28:13,226 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:13,226 - __main__ - INFO - Starting run: train_horizon_4_20251210_162813
2025-12-10 16:28:13,276 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:13,276 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/9556566d3e414039bdd0e8412cd0c05d/artifacts
2025-12-10 16:28:13,549 - src.models.train - INFO - Starting training for horizon 4 days
2025-12-10 16:28:13,549 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:13,549 - src.models.train - INFO - Creating shifted target for horizon=4 days
2025-12-10 16:28:13,551 - src.models.train - INFO - Created target for horizon 4: 1265 samples (4 rows removed due to shifting)
2025-12-10 16:28:13,551 - src.models.train - INFO - Data split: Train=759 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:28:13,552 - src.models.train - INFO - Features: 33
2025-12-10 16:28:13,552 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:13,553 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,553 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:13,679 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:13,681 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,681 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:13,706 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:13,708 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,708 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:13,788 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:13,790 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,790 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:13,842 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:13,844 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,845 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:13,884 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:13,886 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:13,886 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,008 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,010 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:14,010 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,083 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,085 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:14,085 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,159 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,162 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:14,162 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,292 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,295 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:14,295 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,316 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,317 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:14,317 - src.models.train - INFO - Best validation MAE: 6.6643
2025-12-10 16:28:14,317 - src.models.train - INFO - Best parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}
2025-12-10 16:28:14,318 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:14,318 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:28:14,318 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=4)
2025-12-10 16:28:14,339 - src.models.lightgbm_model - INFO - Point model trained with 759 samples
2025-12-10 16:28:14,339 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:14,339 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:14,339 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:14,368 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:14,369 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:28:14,371 - src.models.evaluation - INFO - Evaluation: MAE=6.80, RMSE=9.15, Coverage=96.5%, Width=36.36
2025-12-10 16:28:14,372 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:14,372 - src.models.train - INFO -   MAE: 6.7997
2025-12-10 16:28:14,372 - src.models.train - INFO -   RMSE: 9.1516
2025-12-10 16:28:14,372 - src.models.train - INFO -   Coverage: 96.46%
2025-12-10 16:28:14,372 - src.models.train - INFO -   Interval Width: 36.36
2025-12-10 16:28:14,372 - src.models.train - INFO - Training complete for horizon 4
2025-12-10 16:28:14,381 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:14,696 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.6643, test_mae=6.7997, test_rmse=9.1516, test_coverage=0.9646, test_interval_width=36.3634
2025-12-10 16:28:14,696 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 4: MAE=6.80, RMSE=9.15
2025-12-10 16:28:14,696 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_4.pkl
2025-12-10 16:28:14,699 - src.models.lightgbm_model - INFO - Model saved successfully (193.5 KB)
2025-12-10 16:28:16,575 - __main__ - INFO - Model registered: er_forecast_horizon_4 v12
2025-12-10 16:28:16,575 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 4, stage Staging
2025-12-10 16:28:16,670 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:16,670 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:16,670 - src.models.model_promotion - INFO - Test MAE: 6.7997, Threshold: 15.0000
2025-12-10 16:28:16,670 - src.models.model_promotion - INFO - Model meets quality threshold (6.7997 < 15.0000)
2025-12-10 16:28:16,671 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.7997 < 15.0000)
2025-12-10 16:28:16,671 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_4 version 12
2025-12-10 16:28:16,765 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:16,861 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:16,956 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_4 v12
2025-12-10 16:28:16,956 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 4
2025-12-10 16:28:16,956 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 4, stage Production
üèÉ View run train_horizon_4_20251210_162813 at: http://host.docker.internal:5050/#/experiments/1/runs/9556566d3e414039bdd0e8412cd0c05d
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:17,058 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:17,058 - __main__ - INFO - Training Horizon 5 Days Ahead
2025-12-10 16:28:17,058 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:17,058 - __main__ - INFO - Starting run: train_horizon_5_20251210_162817
2025-12-10 16:28:17,107 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:17,107 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/3633d11e732f4908976d2eeaa139a752/artifacts
2025-12-10 16:28:17,380 - src.models.train - INFO - Starting training for horizon 5 days
2025-12-10 16:28:17,380 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:17,380 - src.models.train - INFO - Creating shifted target for horizon=5 days
2025-12-10 16:28:17,382 - src.models.train - INFO - Created target for horizon 5: 1264 samples (5 rows removed due to shifting)
2025-12-10 16:28:17,382 - src.models.train - INFO - Data split: Train=758 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:28:17,383 - src.models.train - INFO - Features: 33
2025-12-10 16:28:17,383 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:17,384 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,384 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,510 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,512 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,512 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,539 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,541 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,541 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,617 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,619 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,619 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,672 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,674 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,674 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,712 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,714 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,714 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,835 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,838 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,838 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,917 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,919 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,919 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:17,992 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:17,994 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:17,994 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:18,131 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:18,133 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:18,133 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:18,155 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:18,157 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:18,157 - src.models.train - INFO - Best validation MAE: 6.8729
2025-12-10 16:28:18,157 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:28:18,157 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:18,157 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:28:18,157 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=5)
2025-12-10 16:28:18,233 - src.models.lightgbm_model - INFO - Point model trained with 758 samples
2025-12-10 16:28:18,233 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:18,233 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:18,233 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:18,293 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:18,293 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:28:18,296 - src.models.evaluation - INFO - Evaluation: MAE=6.84, RMSE=9.23, Coverage=96.9%, Width=38.71
2025-12-10 16:28:18,297 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:18,297 - src.models.train - INFO -   MAE: 6.8373
2025-12-10 16:28:18,297 - src.models.train - INFO -   RMSE: 9.2277
2025-12-10 16:28:18,297 - src.models.train - INFO -   Coverage: 96.85%
2025-12-10 16:28:18,297 - src.models.train - INFO -   Interval Width: 38.71
2025-12-10 16:28:18,297 - src.models.train - INFO - Training complete for horizon 5
2025-12-10 16:28:18,306 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:18,622 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.8729, test_mae=6.8373, test_rmse=9.2277, test_coverage=0.9685, test_interval_width=38.7130
2025-12-10 16:28:18,622 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 5: MAE=6.84, RMSE=9.23
2025-12-10 16:28:18,623 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_5.pkl
2025-12-10 16:28:18,631 - src.models.lightgbm_model - INFO - Model saved successfully (531.5 KB)
2025-12-10 16:28:20,495 - __main__ - INFO - Model registered: er_forecast_horizon_5 v12
2025-12-10 16:28:20,495 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 5, stage Staging
2025-12-10 16:28:20,590 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:20,590 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:20,590 - src.models.model_promotion - INFO - Test MAE: 6.8373, Threshold: 15.0000
2025-12-10 16:28:20,590 - src.models.model_promotion - INFO - Model meets quality threshold (6.8373 < 15.0000)
2025-12-10 16:28:20,590 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.8373 < 15.0000)
2025-12-10 16:28:20,590 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_5 version 12
2025-12-10 16:28:20,685 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:20,780 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:20,875 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_5 v12
2025-12-10 16:28:20,875 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 5
2025-12-10 16:28:20,875 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 5, stage Production
üèÉ View run train_horizon_5_20251210_162817 at: http://host.docker.internal:5050/#/experiments/1/runs/3633d11e732f4908976d2eeaa139a752
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:20,974 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:20,974 - __main__ - INFO - Training Horizon 6 Days Ahead
2025-12-10 16:28:20,974 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:20,974 - __main__ - INFO - Starting run: train_horizon_6_20251210_162820
2025-12-10 16:28:21,022 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:21,022 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/df833d11f42143beb5c80951867812fa/artifacts
2025-12-10 16:28:21,290 - src.models.train - INFO - Starting training for horizon 6 days
2025-12-10 16:28:21,290 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:21,290 - src.models.train - INFO - Creating shifted target for horizon=6 days
2025-12-10 16:28:21,292 - src.models.train - INFO - Created target for horizon 6: 1263 samples (6 rows removed due to shifting)
2025-12-10 16:28:21,292 - src.models.train - INFO - Data split: Train=757 (59.9%), Val=126 (10.0%), Calib=126 (10.0%), Test=254 (20.1%)
2025-12-10 16:28:21,293 - src.models.train - INFO - Features: 33
2025-12-10 16:28:21,293 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:21,294 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,294 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,413 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,415 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,415 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,441 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,443 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,443 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,521 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,524 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,524 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,626 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,629 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,629 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,666 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,668 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,669 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,786 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,788 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,788 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,860 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,862 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,862 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:21,931 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:21,933 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:21,933 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:22,062 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:22,065 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:22,065 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:22,085 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:22,087 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:22,087 - src.models.train - INFO - Best validation MAE: 6.8089
2025-12-10 16:28:22,087 - src.models.train - INFO - Best parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}
2025-12-10 16:28:22,087 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:22,087 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:28:22,087 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=6)
2025-12-10 16:28:22,157 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:22,157 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:22,157 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:22,157 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:22,220 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:22,220 - src.models.evaluation - INFO - Evaluating model on 254 test samples
2025-12-10 16:28:22,223 - src.models.evaluation - INFO - Evaluation: MAE=6.63, RMSE=9.00, Coverage=96.9%, Width=38.64
2025-12-10 16:28:22,223 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:22,223 - src.models.train - INFO -   MAE: 6.6328
2025-12-10 16:28:22,223 - src.models.train - INFO -   RMSE: 8.9996
2025-12-10 16:28:22,223 - src.models.train - INFO -   Coverage: 96.85%
2025-12-10 16:28:22,223 - src.models.train - INFO -   Interval Width: 38.64
2025-12-10 16:28:22,223 - src.models.train - INFO - Training complete for horizon 6
2025-12-10 16:28:22,231 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:22,529 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.8089, test_mae=6.6328, test_rmse=8.9996, test_coverage=0.9685, test_interval_width=38.6386
2025-12-10 16:28:22,529 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 6: MAE=6.63, RMSE=9.00
2025-12-10 16:28:22,529 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_6.pkl
2025-12-10 16:28:22,535 - src.models.lightgbm_model - INFO - Model saved successfully (540.1 KB)
2025-12-10 16:28:24,415 - __main__ - INFO - Model registered: er_forecast_horizon_6 v12
2025-12-10 16:28:24,415 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 6, stage Staging
2025-12-10 16:28:24,510 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:24,510 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:24,510 - src.models.model_promotion - INFO - Test MAE: 6.6328, Threshold: 15.0000
2025-12-10 16:28:24,510 - src.models.model_promotion - INFO - Model meets quality threshold (6.6328 < 15.0000)
2025-12-10 16:28:24,510 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.6328 < 15.0000)
2025-12-10 16:28:24,510 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_6 version 12
2025-12-10 16:28:24,605 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:24,701 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:24,795 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_6 v12
2025-12-10 16:28:24,795 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 6
2025-12-10 16:28:24,795 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 6, stage Production
üèÉ View run train_horizon_6_20251210_162820 at: http://host.docker.internal:5050/#/experiments/1/runs/df833d11f42143beb5c80951867812fa
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:24,896 - __main__ - INFO - 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:24,896 - __main__ - INFO - Training Horizon 7 Days Ahead
2025-12-10 16:28:24,896 - __main__ - INFO - ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2025-12-10 16:28:24,896 - __main__ - INFO - Starting run: train_horizon_7_20251210_162824
2025-12-10 16:28:24,945 - __main__ - INFO - Run experiment ID: 1
2025-12-10 16:28:24,945 - __main__ - INFO - Run artifact URI: s3://mlflow-artifacts/1/35b357006b9a4c0892924ef74c83a7fd/artifacts
2025-12-10 16:28:25,218 - src.models.train - INFO - Starting training for horizon 7 days
2025-12-10 16:28:25,218 - src.models.train - INFO - Data shape: (1269, 35), Optuna trials: 10
2025-12-10 16:28:25,218 - src.models.train - INFO - Creating shifted target for horizon=7 days
2025-12-10 16:28:25,220 - src.models.train - INFO - Created target for horizon 7: 1262 samples (7 rows removed due to shifting)
2025-12-10 16:28:25,220 - src.models.train - INFO - Data split: Train=757 (60.0%), Val=126 (10.0%), Calib=126 (10.0%), Test=253 (20.0%)
2025-12-10 16:28:25,221 - src.models.train - INFO - Features: 33
2025-12-10 16:28:25,221 - src.models.train - INFO - Starting Optuna hyperparameter search (10 trials)
2025-12-10 16:28:25,222 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,222 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,345 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,348 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,348 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,371 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,374 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,374 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,443 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,445 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,446 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,497 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,500 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,500 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,537 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,540 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,540 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,662 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,665 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,665 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,737 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,739 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,739 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,810 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,812 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,812 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,934 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,936 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,936 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:25,957 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:25,959 - src.models.train - INFO - Optuna search complete!
2025-12-10 16:28:25,959 - src.models.train - INFO - Best validation MAE: 6.4421
2025-12-10 16:28:25,959 - src.models.train - INFO - Best parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}
2025-12-10 16:28:25,959 - src.models.train - INFO - Training final model with best parameters
2025-12-10 16:28:25,959 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:28:25,959 - src.models.lightgbm_model - INFO - Training point prediction model (horizon=7)
2025-12-10 16:28:26,082 - src.models.lightgbm_model - INFO - Point model trained with 757 samples
2025-12-10 16:28:26,082 - src.models.train - INFO - Training quantile models for confidence intervals
2025-12-10 16:28:26,082 - src.models.lightgbm_model - INFO - Training quantile regression models for confidence intervals
2025-12-10 16:28:26,082 - src.models.lightgbm_model - INFO - Quantiles: 0.025, 0.975 (95% CI)
2025-12-10 16:28:26,108 - src.models.lightgbm_model - INFO - Quantile models trained successfully
2025-12-10 16:28:26,108 - src.models.evaluation - INFO - Evaluating model on 253 test samples
2025-12-10 16:28:26,111 - src.models.evaluation - INFO - Evaluation: MAE=6.95, RMSE=9.26, Coverage=96.4%, Width=40.14
2025-12-10 16:28:26,111 - src.models.train - INFO - Test set evaluation:
2025-12-10 16:28:26,111 - src.models.train - INFO -   MAE: 6.9527
2025-12-10 16:28:26,111 - src.models.train - INFO -   RMSE: 9.2642
2025-12-10 16:28:26,111 - src.models.train - INFO -   Coverage: 96.44%
2025-12-10 16:28:26,111 - src.models.train - INFO -   Interval Width: 40.14
2025-12-10 16:28:26,111 - src.models.train - INFO - Training complete for horizon 7
2025-12-10 16:28:26,121 - src.utils.mlflow_utils - INFO - Logged 10 parameters to MLflow
2025-12-10 16:28:26,432 - src.utils.mlflow_utils - INFO - Logged metrics: best_val_mae=6.4421, test_mae=6.9527, test_rmse=9.2642, test_coverage=0.9644, test_interval_width=40.1352
2025-12-10 16:28:26,432 - src.monitoring.metrics_collector - INFO - Recorded training metrics for horizon 7: MAE=6.95, RMSE=9.26
2025-12-10 16:28:26,432 - src.models.lightgbm_model - INFO - Saving model to: models/forecaster_horizon_7.pkl
2025-12-10 16:28:26,437 - src.models.lightgbm_model - INFO - Model saved successfully (522.6 KB)
2025-12-10 16:28:28,310 - __main__ - INFO - Model registered: er_forecast_horizon_7 v12
2025-12-10 16:28:28,310 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 7, stage Staging
2025-12-10 16:28:28,405 - src.models.model_promotion - WARNING - MAE tag not found for production model (version 11)
2025-12-10 16:28:28,405 - src.models.model_promotion - INFO - Evaluating model for promotion
2025-12-10 16:28:28,405 - src.models.model_promotion - INFO - Test MAE: 6.9527, Threshold: 15.0000
2025-12-10 16:28:28,405 - src.models.model_promotion - INFO - Model meets quality threshold (6.9527 < 15.0000)
2025-12-10 16:28:28,405 - __main__ - INFO - [PROMOTE] Model to production (MAE: 6.9527 < 15.0000)
2025-12-10 16:28:28,405 - src.models.model_promotion - INFO - Promoting model to production: er_forecast_horizon_7 version 12
2025-12-10 16:28:28,500 - src.models.model_promotion - INFO - Archiving existing production model: version 11
2025-12-10 16:28:28,595 - src.models.model_promotion - INFO - Version 11 archived
2025-12-10 16:28:28,689 - src.models.model_promotion - INFO - Model promoted to Production: er_forecast_horizon_7 v12
2025-12-10 16:28:28,689 - src.monitoring.metrics_collector - INFO - Recorded model promotion: horizon 7
2025-12-10 16:28:28,689 - src.monitoring.metrics_collector - INFO - Recorded model registration: horizon 7, stage Production
üèÉ View run train_horizon_7_20251210_162824 at: http://host.docker.internal:5050/#/experiments/1/runs/35b357006b9a4c0892924ef74c83a7fd
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/1
2025-12-10 16:28:28,790 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:28,790 - __main__ - INFO - STEP 6: Archiving Old Model Versions
2025-12-10 16:28:28,790 - __main__ - INFO - ======================================================================
2025-12-10 16:28:28,790 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_1
2025-12-10 16:28:28,790 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,798 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,798 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,798 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_2
2025-12-10 16:28:28,798 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,805 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,805 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,805 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_3
2025-12-10 16:28:28,805 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,813 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,813 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,813 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_4
2025-12-10 16:28:28,813 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,820 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,820 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,820 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_5
2025-12-10 16:28:28,820 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,827 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,827 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,827 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_6
2025-12-10 16:28:28,827 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,834 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,834 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,834 - src.models.model_promotion - INFO - Archiving old model versions for: er_forecast_horizon_7
2025-12-10 16:28:28,834 - src.models.model_promotion - INFO - Keeping most recent 52 versions
2025-12-10 16:28:28,841 - src.models.model_promotion - INFO - Found 12 total versions
2025-12-10 16:28:28,841 - src.models.model_promotion - INFO - No models to archive
2025-12-10 16:28:28,841 - __main__ - INFO - Archived 0 old model versions across all horizons
2025-12-10 16:28:28,842 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:28,842 - __main__ - INFO - STEP 7: Creating Summary Report
2025-12-10 16:28:28,842 - __main__ - INFO - ======================================================================
2025-12-10 16:28:28,842 - __main__ - INFO - Training summary saved to: logs/training_summary_20251210_162828.md
2025-12-10 16:28:28,842 - __main__ - INFO - 
======================================================================
2025-12-10 16:28:28,842 - __main__ - INFO - TRAINING FLOW COMPLETE! 
2025-12-10 16:28:28,842 - __main__ - INFO - ======================================================================
2025-12-10 16:28:28,842 - src.monitoring.metrics_collector - INFO - Recorded flow run status: training_flow - success
2025-12-10 16:28:28,842 - __main__ - INFO - Training completed successfully: 7 models trained, 7 promoted

2025-12-10 16:28:29,232 [ERROR] Training STDERR:
time="2025-12-10T16:27:53Z" level=warning msg="Found orphan containers ([er-forecast-prediction-run-aaab7f9f3565 er-forecast-training-run-4766d86e3dc8 er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.60ms
2025/12/10 16:28:00 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet

[I 2025-12-10 16:28:01,100] A new study created in memory with name: no-name-c438ecaa-4084-4895-8c8d-e1f1496e2052
[I 2025-12-10 16:28:01,291] Trial 0 finished with value: 6.512265283093906 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.512265283093906.
[I 2025-12-10 16:28:01,321] Trial 1 finished with value: 10.085492193040922 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.512265283093906.
[I 2025-12-10 16:28:01,400] Trial 2 finished with value: 6.505030047788321 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,455] Trial 3 finished with value: 6.86794718519191 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,497] Trial 4 finished with value: 6.666344221508085 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,623] Trial 5 finished with value: 7.292237453838007 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,702] Trial 6 finished with value: 6.834370750941091 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,776] Trial 7 finished with value: 6.878080904495041 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,917] Trial 8 finished with value: 8.290999070572832 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.505030047788321.
[I 2025-12-10 16:28:01,941] Trial 9 finished with value: 6.633105855632679 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.505030047788321.
2025/12/10 16:28:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:02 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_1' already exists. Creating a new version of this model...
2025/12/10 16:28:04 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_1, version 12
Created version '12' of model 'er_forecast_horizon_1'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:05,692] A new study created in memory with name: no-name-17ade99b-3f37-402f-9634-4a1a76e96f0f
[I 2025-12-10 16:28:05,827] Trial 0 finished with value: 6.782316802758262 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.782316802758262.
[I 2025-12-10 16:28:05,856] Trial 1 finished with value: 9.998013056291104 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.782316802758262.
[I 2025-12-10 16:28:05,931] Trial 2 finished with value: 6.648412014759784 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:05,987] Trial 3 finished with value: 7.563951983408843 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,030] Trial 4 finished with value: 7.5330410276384825 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,160] Trial 5 finished with value: 7.547934169796517 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,237] Trial 6 finished with value: 6.82705517668433 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,329] Trial 7 finished with value: 7.4158195121780714 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,501] Trial 8 finished with value: 8.108724772794112 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.648412014759784.
[I 2025-12-10 16:28:06,525] Trial 9 finished with value: 6.722453796244694 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.648412014759784.
2025/12/10 16:28:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_2' already exists. Creating a new version of this model...
2025/12/10 16:28:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_2, version 12
Created version '12' of model 'er_forecast_horizon_2'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:09,651] A new study created in memory with name: no-name-b72314d3-18dd-4026-8e53-c2411c9db9ce
[I 2025-12-10 16:28:09,780] Trial 0 finished with value: 7.0457087833301895 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 7.0457087833301895.
[I 2025-12-10 16:28:09,809] Trial 1 finished with value: 10.014195910665732 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 7.0457087833301895.
[I 2025-12-10 16:28:09,884] Trial 2 finished with value: 6.648803536132593 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:09,938] Trial 3 finished with value: 7.904063453959654 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:09,980] Trial 4 finished with value: 7.499845018525743 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:10,106] Trial 5 finished with value: 7.721197567347179 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:10,184] Trial 6 finished with value: 6.941374383645906 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:10,257] Trial 7 finished with value: 7.318939231628028 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:10,386] Trial 8 finished with value: 8.179073537322086 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.648803536132593.
[I 2025-12-10 16:28:10,409] Trial 9 finished with value: 6.767924424639475 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.648803536132593.
2025/12/10 16:28:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:12 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_3' already exists. Creating a new version of this model...
2025/12/10 16:28:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_3, version 12
Created version '12' of model 'er_forecast_horizon_3'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:13,552] A new study created in memory with name: no-name-aa0d4cda-eeb5-4b05-b156-e6e18c739a9b
[I 2025-12-10 16:28:13,680] Trial 0 finished with value: 6.891976215905066 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.891976215905066.
[I 2025-12-10 16:28:13,708] Trial 1 finished with value: 10.07568987588107 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.891976215905066.
[I 2025-12-10 16:28:13,789] Trial 2 finished with value: 6.714104392351724 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:13,844] Trial 3 finished with value: 6.913568773375855 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:13,885] Trial 4 finished with value: 6.871145871991883 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:14,009] Trial 5 finished with value: 6.9798221446676 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:14,084] Trial 6 finished with value: 6.919413472587999 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:14,161] Trial 7 finished with value: 6.8440033976624255 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:14,294] Trial 8 finished with value: 8.238547699839744 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.714104392351724.
[I 2025-12-10 16:28:14,317] Trial 9 finished with value: 6.66429078792307 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 9 with value: 6.66429078792307.
2025/12/10 16:28:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:16 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_4' already exists. Creating a new version of this model...
2025/12/10 16:28:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_4, version 12
Created version '12' of model 'er_forecast_horizon_4'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:17,383] A new study created in memory with name: no-name-74a47b02-8602-461a-93fd-2a72e36fe175
[I 2025-12-10 16:28:17,512] Trial 0 finished with value: 7.16259264805606 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 7.16259264805606.
[I 2025-12-10 16:28:17,541] Trial 1 finished with value: 10.104027523554073 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 7.16259264805606.
[I 2025-12-10 16:28:17,619] Trial 2 finished with value: 6.872930172388908 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:17,673] Trial 3 finished with value: 7.34826692491851 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:17,713] Trial 4 finished with value: 7.349687825358949 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:17,837] Trial 5 finished with value: 7.642954778066336 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:17,918] Trial 6 finished with value: 7.071456341505532 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:17,993] Trial 7 finished with value: 7.494545305669174 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:18,132] Trial 8 finished with value: 8.276343580428234 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.872930172388908.
[I 2025-12-10 16:28:18,157] Trial 9 finished with value: 6.999303650518748 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.872930172388908.
2025/12/10 16:28:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:18 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:20 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_5' already exists. Creating a new version of this model...
2025/12/10 16:28:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_5, version 12
Created version '12' of model 'er_forecast_horizon_5'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:21,293] A new study created in memory with name: no-name-873bb1b8-d807-402a-ad3f-661641fa95e0
[I 2025-12-10 16:28:21,414] Trial 0 finished with value: 6.997173869266218 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.997173869266218.
[I 2025-12-10 16:28:21,442] Trial 1 finished with value: 10.133613571261762 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.997173869266218.
[I 2025-12-10 16:28:21,523] Trial 2 finished with value: 6.808851332471394 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:21,628] Trial 3 finished with value: 7.37353060303102 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:21,668] Trial 4 finished with value: 7.191029665851202 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:21,787] Trial 5 finished with value: 7.731251202584651 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:21,861] Trial 6 finished with value: 7.121457728899293 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:21,932] Trial 7 finished with value: 7.56536537483717 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:22,064] Trial 8 finished with value: 8.400166033962144 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 2 with value: 6.808851332471394.
[I 2025-12-10 16:28:22,086] Trial 9 finished with value: 6.87010953323339 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 2 with value: 6.808851332471394.
2025/12/10 16:28:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:22 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:24 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_6' already exists. Creating a new version of this model...
2025/12/10 16:28:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_6, version 12
Created version '12' of model 'er_forecast_horizon_6'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
[I 2025-12-10 16:28:25,221] A new study created in memory with name: no-name-d94e2c23-7d05-482f-8a3f-7fdb62db99de
[I 2025-12-10 16:28:25,347] Trial 0 finished with value: 6.4420807748022 and parameters: {'n_estimators': 220, 'max_depth': 12, 'num_leaves': 150, 'learning_rate': 0.030405325392865647, 'min_child_samples': 20, 'subsample': 0.55, 'colsample_bytree': 0.5, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.0, 'min_child_weight': 0.679657809075816}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,373] Trial 1 finished with value: 9.90331073321374 and parameters: {'n_estimators': 50, 'max_depth': 12, 'num_leaves': 170, 'learning_rate': 0.0033572967053517922, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.65, 'reg_alpha': 5.300000000000001, 'reg_lambda': 4.3, 'min_child_weight': 0.014618962793704957}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,445] Trial 2 finished with value: 6.565271871839189 and parameters: {'n_estimators': 330, 'max_depth': 4, 'num_leaves': 70, 'learning_rate': 0.008082071885709252, 'min_child_samples': 50, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.1000000000000005, 'reg_lambda': 5.9, 'min_child_weight': 0.0015339162591163618}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,499] Trial 3 finished with value: 7.252551914513719 and parameters: {'n_estimators': 320, 'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.22413234378101138, 'min_child_samples': 100, 'subsample': 0.9, 'colsample_bytree': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 6.9, 'min_child_weight': 0.057624872164786026}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,539] Trial 4 finished with value: 6.711293044129217 and parameters: {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 20, 'learning_rate': 0.1788532743297921, 'min_child_samples': 30, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'reg_alpha': 5.2, 'reg_lambda': 5.5, 'min_child_weight': 0.0054880470007660455}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,664] Trial 5 finished with value: 6.990633290417701 and parameters: {'n_estimators': 490, 'max_depth': 10, 'num_leaves': 190, 'learning_rate': 0.16466293382966793, 'min_child_samples': 60, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.9000000000000001, 'reg_lambda': 0.4, 'min_child_weight': 0.02001342062287998}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,738] Trial 6 finished with value: 6.70430998070908 and parameters: {'n_estimators': 220, 'max_depth': 5, 'num_leaves': 170, 'learning_rate': 0.0076510536667541975, 'min_child_samples': 30, 'subsample': 0.75, 'colsample_bytree': 0.55, 'reg_alpha': 8.1, 'reg_lambda': 0.7000000000000001, 'min_child_weight': 8.862326508576253}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,812] Trial 7 finished with value: 6.836893448002367 and parameters: {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.10471209213501693, 'min_child_samples': 75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 3.6, 'min_child_weight': 0.0029072088906598446}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,936] Trial 8 finished with value: 8.051646297117072 and parameters: {'n_estimators': 440, 'max_depth': 9, 'num_leaves': 80, 'learning_rate': 0.0014369502768990666, 'min_child_samples': 35, 'subsample': 0.65, 'colsample_bytree': 0.9, 'reg_alpha': 6.4, 'reg_lambda': 8.9, 'min_child_weight': 0.0774211647399625}. Best is trial 0 with value: 6.4420807748022.
[I 2025-12-10 16:28:25,959] Trial 9 finished with value: 6.510827182108662 and parameters: {'n_estimators': 100, 'max_depth': 10, 'num_leaves': 160, 'learning_rate': 0.024566974547738343, 'min_child_samples': 80, 'subsample': 0.75, 'colsample_bytree': 0.75, 'reg_alpha': 4.3, 'reg_lambda': 0.2, 'min_child_weight': 0.0027012557725439087}. Best is trial 0 with value: 6.4420807748022.
2025/12/10 16:28:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
2025/12/10 16:28:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!
2025/12/10 16:28:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.
[31m2025/12/10 16:28:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Registered model 'er_forecast_horizon_7' already exists. Creating a new version of this model...
2025/12/10 16:28:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: er_forecast_horizon_7, version 12
Created version '12' of model 'er_forecast_horizon_7'.
/app/flows/training_flow.py:300: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
/app/src/models/model_promotion.py:203: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  production_versions = client.get_latest_versions(
/app/src/models/model_promotion.py:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  existing_production = client.get_latest_versions(
/app/src/models/model_promotion.py:83: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(
/app/src/models/model_promotion.py:93: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  client.transition_model_version_stage(

2025-12-10 16:28:29,232 [INFO] Training completed successfully
2025-12-10 16:28:29,232 [INFO] 10.30.53.44 - - [10/Dec/2025 16:28:29] "GET /train HTTP/1.1" 200 -
2025-12-10 16:31:40,443 [INFO] Received /predict request
2025-12-10 16:31:50,634 [INFO] Prediction STDOUT:
2025-12-10 16:31:45,235 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-10 16:31:45,236 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-10 16:31:45,236 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-10 16:31:45,236 - __main__ - INFO - ======================================================================
2025-12-10 16:31:45,236 - __main__ - INFO - STARTING ER PATIENT FORECAST PREDICTION FLOW
2025-12-10 16:31:45,236 - __main__ - INFO - ======================================================================
2025-12-10 16:31:45,236 - __main__ - INFO - Prediction base date: 2025-12-10
2025-12-10 16:31:45,236 - __main__ - INFO - Output path: data/predictions/
2025-12-10 16:31:45,236 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:45,236 - __main__ - INFO - STEP 1: Loading Latest Patient Data
2025-12-10 16:31:45,236 - __main__ - INFO - ======================================================================
2025-12-10 16:31:45,236 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-10 16:31:45,237 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-10 16:31:46,936 - src.data.preprocessing - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:31:46,971 - __main__ - INFO - Successfully loaded 277,534 rows from database
2025-12-10 16:31:46,972 - src.data.preprocessing - INFO - Removing duplicates from 277,534 rows
2025-12-10 16:31:46,989 - src.data.preprocessing - WARNING - Found 200,196 duplicate rows (72.13%)
2025-12-10 16:31:46,992 - src.data.preprocessing - INFO - After removing duplicates: 77,338 rows remain
2025-12-10 16:31:46,994 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-10 16:31:47,056 - src.data.preprocessing - INFO - Aggregated to 1,287 days
2025-12-10 16:31:47,056 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-10 00:00:00
2025-12-10 16:31:47,057 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-10 16:31:47,057 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-10 16:31:47,057 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-10 16:31:47,058 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-10 16:31:47,060 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-10 16:31:47,063 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-10 16:31:47,064 - src.data.preprocessing - INFO - Final time series: 1,297 days from 2022-05-24 to 2025-12-10
2025-12-10 16:31:47,064 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-10 16:31:47,064 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-10 16:31:47,064 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-10 16:31:47,065 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-10 16:31:47,065 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-10 16:31:47,065 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-10 16:31:47,066 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-10 16:31:47,066 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-10 16:31:47,066 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-10 16:31:47,066 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-10 16:31:47,067 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-10 16:31:47,067 - __main__ - INFO - Loaded data: 1297 days up to 2025-12-10
2025-12-10 16:31:47,067 - __main__ - INFO - Data validation passed: 1297 rows, most recent date 2025-12-10 (0 days ago)
2025-12-10 16:31:47,067 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:47,067 - __main__ - INFO - STEP 2: Fetching Weather Data (Historical + Forecast)
2025-12-10 16:31:47,067 - __main__ - INFO - ======================================================================
2025-12-10 16:31:47,067 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-10
2025-12-10 16:31:47,067 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:31:47,244 - src.data.weather_integration - INFO - Successfully fetched weather data: 1297 days
2025-12-10 16:31:47,245 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-10 16:31:47,247 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-10
2025-12-10 16:31:47,247 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-10
2025-12-10 16:31:47,248 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-10 16:31:47,248 - __main__ - INFO - Historical weather data: 1297 days
2025-12-10 16:31:47,248 - src.data.weather_integration - INFO - Fetching weather forecast for next 8 days
2025-12-10 16:31:47,248 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-10 16:31:47,373 - src.data.weather_integration - INFO - Successfully fetched weather forecast: 8 days
2025-12-10 16:31:47,374 - __main__ - INFO - Weather forecast fetched: 8 days
2025-12-10 16:31:47,374 - __main__ - INFO - Forecast date range: 2025-12-10 to 2025-12-17
2025-12-10 16:31:47,374 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:47,374 - __main__ - INFO - STEP 3: Engineering Features
2025-12-10 16:31:47,374 - __main__ - INFO - ======================================================================
2025-12-10 16:31:47,374 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-10 16:31:47,374 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-10 16:31:47,378 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-10 16:31:47,378 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-10 16:31:47,379 - src.data.feature_engineering - INFO - Weekend days: 370/1297 (28.5%)
2025-12-10 16:31:47,379 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-10 16:31:47,381 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-10 16:31:47,381 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Adding change features
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Added change features
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Final shape: (1297, 35)
2025-12-10 16:31:47,382 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-10 16:31:47,383 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-10 16:31:47,383 - src.data.feature_engineering - INFO - Rows with NaN: 28/1297 (2.2%)
2025-12-10 16:31:47,384 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-10 16:31:47,384 - src.data.feature_engineering - INFO - Remaining rows: 1269
2025-12-10 16:31:47,384 - __main__ - INFO - Features engineered: (1269, 35)
2025-12-10 16:31:47,384 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:47,384 - __main__ - INFO - STEP 4: Loading Production Models from MLflow
2025-12-10 16:31:47,384 - __main__ - INFO - ======================================================================
2025-12-10 16:31:47,384 - src.models.predict - INFO - Loading production models from MLflow Model Registry
2025-12-10 16:31:47,384 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_1
2025-12-10 16:31:47,449 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:47,762 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-10 16:31:47,883 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-10 16:31:47,883 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_1 v12
2025-12-10 16:31:47,883 - src.models.predict - INFO - Loaded model for horizon 1
2025-12-10 16:31:47,883 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_2
2025-12-10 16:31:47,937 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:48,104 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-10 16:31:48,104 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_2 v12
2025-12-10 16:31:48,104 - src.models.predict - INFO - Loaded model for horizon 2
2025-12-10 16:31:48,104 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_3
2025-12-10 16:31:48,198 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:48,363 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-10 16:31:48,363 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_3 v12
2025-12-10 16:31:48,363 - src.models.predict - INFO - Loaded model for horizon 3
2025-12-10 16:31:48,363 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_4
2025-12-10 16:31:48,456 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:48,620 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-10 16:31:48,621 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_4 v12
2025-12-10 16:31:48,621 - src.models.predict - INFO - Loaded model for horizon 4
2025-12-10 16:31:48,621 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_5
2025-12-10 16:31:48,714 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:48,896 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-10 16:31:48,896 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_5 v12
2025-12-10 16:31:48,896 - src.models.predict - INFO - Loaded model for horizon 5
2025-12-10 16:31:48,896 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_6
2025-12-10 16:31:48,950 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:49,117 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-10 16:31:49,117 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_6 v12
2025-12-10 16:31:49,117 - src.models.predict - INFO - Loaded model for horizon 6
2025-12-10 16:31:49,117 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_7
2025-12-10 16:31:49,210 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-10 16:31:49,376 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-10 16:31:49,376 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_7 v12
2025-12-10 16:31:49,376 - src.models.predict - INFO - Loaded model for horizon 7
2025-12-10 16:31:49,376 - src.models.predict - INFO - Successfully loaded all 7 production models from MLflow
2025-12-10 16:31:49,376 - __main__ - INFO - Loaded 7 production models
2025-12-10 16:31:49,376 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:49,376 - __main__ - INFO - STEP 5: Preparing Prediction Features
2025-12-10 16:31:49,376 - __main__ - INFO - ======================================================================
2025-12-10 16:31:49,376 - src.models.predict - INFO - Preparing features for prediction
2025-12-10 16:31:49,376 - src.models.predict - INFO - Base date for predictions: 2025-12-10
2025-12-10 16:31:49,384 - src.models.predict - INFO - Prepared features for 7 prediction days
2025-12-10 16:31:49,384 - src.models.predict - INFO - Prediction date range: 2025-12-11 to 2025-12-17
2025-12-10 16:31:49,384 - src.models.predict - INFO - Weather forecasts applied to prediction features
2025-12-10 16:31:49,385 - src.models.predict - INFO - Total columns in prediction features: 35
2025-12-10 16:31:49,385 - __main__ - INFO - Features prepared for next 7 days
2025-12-10 16:31:49,385 - __main__ - INFO - Each horizon has weather forecast for its target date
2025-12-10 16:31:49,385 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:49,385 - __main__ - INFO - STEP 6: Generating Predictions with Confidence Intervals
2025-12-10 16:31:49,385 - __main__ - INFO - ======================================================================
2025-12-10 16:31:49,385 - src.models.predict - INFO - Generating batch predictions for next 7 days
2025-12-10 16:31:49,385 - src.models.predict - INFO - Feature columns selected: 33 features
2025-12-10 16:31:49,405 - src.models.predict - INFO - Generated 7 predictions
2025-12-10 16:31:49,405 - src.models.predict - INFO - Prediction range: 51.6 to 70.9 patients
2025-12-10 16:31:49,406 - src.monitoring.metrics_collector - INFO - Recorded prediction metrics: 7 predictions in 0.02s
2025-12-10 16:31:49,406 - __main__ - INFO - Generated 7 predictions in 0.02s
2025-12-10 16:31:49,407 - __main__ - INFO -    Prediction range: 51.6 to 70.9 patients
2025-12-10 16:31:49,407 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:49,407 - __main__ - INFO - STEP 7: Saving Predictions
2025-12-10 16:31:49,407 - __main__ - INFO - ======================================================================
2025-12-10 16:31:49,407 - src.models.prediction_output - INFO - Saving predictions to CSV
2025-12-10 16:31:49,410 - src.models.prediction_output - INFO - Predictions saved to: data/predictions/predictions_20251210_163149.csv
2025-12-10 16:31:49,410 - src.models.prediction_output - INFO - File size: 0.8 KB, Rows: 7
2025-12-10 16:31:49,410 - __main__ - INFO - Predictions saved to CSV: data/predictions/predictions_20251210_163149.csv
2025-12-10 16:31:49,410 - src.models.prediction_output - INFO - Writing predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:31:49,430 - src.models.prediction_output - INFO - Successfully wrote 7 predictions to [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:31:49,431 - __main__ - INFO - Wrote 7 predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-10 16:31:49,431 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:49,431 - __main__ - INFO - STEP 8: Logging Metadata to MLflow
2025-12-10 16:31:49,431 - __main__ - INFO - ======================================================================
2025-12-10 16:31:49,431 - src.models.prediction_output - INFO - Logging prediction metadata to MLflow
2025-12-10 16:31:50,188 - src.models.prediction_output - INFO - Prediction metadata logged to MLflow run: fe4a503830984d8cad91dc1b3c0c0b35
üèÉ View run batch_prediction_2025-12-10_16:31:49 at: http://host.docker.internal:5050/#/experiments/2/runs/fe4a503830984d8cad91dc1b3c0c0b35
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/2
2025-12-10 16:31:50,241 - __main__ - INFO - Logged to MLflow run: fe4a503830984d8cad91dc1b3c0c0b35
2025-12-10 16:31:50,242 - __main__ - INFO - 
======================================================================
2025-12-10 16:31:50,242 - __main__ - INFO - PREDICTION FLOW COMPLETE! 
2025-12-10 16:31:50,242 - __main__ - INFO - ======================================================================
2025-12-10 16:31:50,242 - __main__ - INFO - Average prediction: 63.1 patients
2025-12-10 16:31:50,242 - __main__ - INFO - Average interval width: 37.507799975995844
2025-12-10 16:31:50,242 - src.monitoring.metrics_collector - INFO - Recorded flow run status: prediction_flow - success
2025-12-10 16:31:50,244 - __main__ - INFO - Prediction completed successfully: 7 predictions

2025-12-10 16:31:50,634 [ERROR] Prediction STDERR:
time="2025-12-10T16:31:40Z" level=warning msg="Found orphan containers ([er-forecast-training-run-f7d17f9a5ac0 er-forecast-prediction-run-aaab7f9f3565 er-forecast-training-run-4766d86e3dc8 er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.78ms
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 25266.89it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 23237.14it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 24769.51it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 26462.49it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 27850.62it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 22944.77it/s]
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 140.59it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 142.96it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 203.41it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 261.54it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 317.18it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 315.50it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 112.98it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 125.56it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 187.35it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 242.76it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 302.10it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 301.09it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 32263.88it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 515.78it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 458.33it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 604.17it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 668.01it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 662.52it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 29127.11it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 26379.27it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 617.84it/s]  
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 716.30it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 840.51it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 831.71it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 111.02it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 216.10it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 202.76it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 263.00it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 315.61it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 314.29it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 37117.73it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 208.13it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 277.73it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 353.59it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 427.31it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 424.11it/s]
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
2025/12/10 16:31:49 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet


2025-12-10 16:31:50,634 [INFO] Prediction completed successfully
2025-12-10 16:31:50,634 [INFO] 10.30.53.44 - - [10/Dec/2025 16:31:50] "GET /predict HTTP/1.1" 200 -
2025-12-11 06:04:22,759 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.30.51.137:5000
2025-12-11 06:04:22,759 [INFO] [33mPress CTRL+C to quit[0m
2025-12-11 06:04:22,759 [INFO]  * Restarting with stat
2025-12-11 06:04:22,899 [WARNING]  * Debugger is active!
2025-12-11 06:04:22,900 [INFO]  * Debugger PIN: 435-505-377
2025-12-11 14:30:00,716 [INFO] Received /predict request
2025-12-11 14:30:11,722 [INFO] Prediction STDOUT:
2025-12-11 14:30:05,639 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-11 14:30:05,640 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-11 14:30:05,640 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-11 14:30:05,640 - __main__ - INFO - ======================================================================
2025-12-11 14:30:05,640 - __main__ - INFO - STARTING ER PATIENT FORECAST PREDICTION FLOW
2025-12-11 14:30:05,640 - __main__ - INFO - ======================================================================
2025-12-11 14:30:05,640 - __main__ - INFO - Prediction base date: 2025-12-11
2025-12-11 14:30:05,640 - __main__ - INFO - Output path: data/predictions/
2025-12-11 14:30:05,640 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:05,640 - __main__ - INFO - STEP 1: Loading Latest Patient Data
2025-12-11 14:30:05,640 - __main__ - INFO - ======================================================================
2025-12-11 14:30:05,640 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-11 14:30:05,641 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-11 14:30:07,467 - src.data.preprocessing - INFO - Successfully loaded 277,688 rows from database
2025-12-11 14:30:07,505 - __main__ - INFO - Successfully loaded 277,688 rows from database
2025-12-11 14:30:07,506 - src.data.preprocessing - INFO - Removing duplicates from 277,688 rows
2025-12-11 14:30:07,527 - src.data.preprocessing - WARNING - Found 200,295 duplicate rows (72.13%)
2025-12-11 14:30:07,530 - src.data.preprocessing - INFO - After removing duplicates: 77,393 rows remain
2025-12-11 14:30:07,532 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-11 14:30:07,594 - src.data.preprocessing - INFO - Aggregated to 1,288 days
2025-12-11 14:30:07,595 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-11 00:00:00
2025-12-11 14:30:07,595 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-11 14:30:07,595 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-11 14:30:07,595 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-11 14:30:07,597 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-11 14:30:07,598 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-11 14:30:07,601 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-11 14:30:07,602 - src.data.preprocessing - INFO - Final time series: 1,298 days from 2022-05-24 to 2025-12-11
2025-12-11 14:30:07,602 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-11 14:30:07,602 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-11 14:30:07,602 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-11 14:30:07,603 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-11 14:30:07,603 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-11 14:30:07,603 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-11 14:30:07,603 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-11 14:30:07,604 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-11 14:30:07,604 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-11 14:30:07,604 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-11 14:30:07,605 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-11 14:30:07,605 - __main__ - INFO - Loaded data: 1298 days up to 2025-12-11
2025-12-11 14:30:07,605 - __main__ - INFO - Data validation passed: 1298 rows, most recent date 2025-12-11 (0 days ago)
2025-12-11 14:30:07,605 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:07,605 - __main__ - INFO - STEP 2: Fetching Weather Data (Historical + Forecast)
2025-12-11 14:30:07,605 - __main__ - INFO - ======================================================================
2025-12-11 14:30:07,605 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-11
2025-12-11 14:30:07,605 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-11 14:30:07,994 - src.data.weather_integration - INFO - Successfully fetched weather data: 1298 days
2025-12-11 14:30:07,995 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-11 14:30:07,997 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-11
2025-12-11 14:30:07,997 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-11
2025-12-11 14:30:07,998 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-11 14:30:07,998 - __main__ - INFO - Historical weather data: 1298 days
2025-12-11 14:30:07,998 - src.data.weather_integration - INFO - Fetching weather forecast for next 8 days
2025-12-11 14:30:07,998 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-11 14:30:08,520 - src.data.weather_integration - INFO - Successfully fetched weather forecast: 8 days
2025-12-11 14:30:08,521 - __main__ - INFO - Weather forecast fetched: 8 days
2025-12-11 14:30:08,521 - __main__ - INFO - Forecast date range: 2025-12-11 to 2025-12-18
2025-12-11 14:30:08,521 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:08,521 - __main__ - INFO - STEP 3: Engineering Features
2025-12-11 14:30:08,521 - __main__ - INFO - ======================================================================
2025-12-11 14:30:08,521 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-11 14:30:08,521 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-11 14:30:08,524 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-11 14:30:08,524 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-11 14:30:08,525 - src.data.feature_engineering - INFO - Weekend days: 370/1298 (28.5%)
2025-12-11 14:30:08,525 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-11 14:30:08,527 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-11 14:30:08,527 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-11 14:30:08,528 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-11 14:30:08,528 - src.data.feature_engineering - INFO - Adding change features
2025-12-11 14:30:08,529 - src.data.feature_engineering - INFO - Added change features
2025-12-11 14:30:08,529 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-11 14:30:08,529 - src.data.feature_engineering - INFO - Final shape: (1298, 35)
2025-12-11 14:30:08,529 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-11 14:30:08,529 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-11 14:30:08,530 - src.data.feature_engineering - INFO - Rows with NaN: 28/1298 (2.2%)
2025-12-11 14:30:08,530 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-11 14:30:08,530 - src.data.feature_engineering - INFO - Remaining rows: 1270
2025-12-11 14:30:08,530 - __main__ - INFO - Features engineered: (1270, 35)
2025-12-11 14:30:08,530 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:08,530 - __main__ - INFO - STEP 4: Loading Production Models from MLflow
2025-12-11 14:30:08,530 - __main__ - INFO - ======================================================================
2025-12-11 14:30:08,530 - src.models.predict - INFO - Loading production models from MLflow Model Registry
2025-12-11 14:30:08,530 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_1
2025-12-11 14:30:08,595 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:08,909 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-11 14:30:09,030 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-11 14:30:09,030 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_1 v12
2025-12-11 14:30:09,030 - src.models.predict - INFO - Loaded model for horizon 1
2025-12-11 14:30:09,030 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_2
2025-12-11 14:30:09,082 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:09,248 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-11 14:30:09,248 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_2 v12
2025-12-11 14:30:09,248 - src.models.predict - INFO - Loaded model for horizon 2
2025-12-11 14:30:09,248 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_3
2025-12-11 14:30:09,342 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:09,507 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-11 14:30:09,507 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_3 v12
2025-12-11 14:30:09,507 - src.models.predict - INFO - Loaded model for horizon 3
2025-12-11 14:30:09,507 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_4
2025-12-11 14:30:09,601 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:09,765 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-11 14:30:09,765 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_4 v12
2025-12-11 14:30:09,765 - src.models.predict - INFO - Loaded model for horizon 4
2025-12-11 14:30:09,765 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_5
2025-12-11 14:30:09,860 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:10,026 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-11 14:30:10,026 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_5 v12
2025-12-11 14:30:10,026 - src.models.predict - INFO - Loaded model for horizon 5
2025-12-11 14:30:10,026 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_6
2025-12-11 14:30:10,120 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:10,286 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-11 14:30:10,286 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_6 v12
2025-12-11 14:30:10,286 - src.models.predict - INFO - Loaded model for horizon 6
2025-12-11 14:30:10,286 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_7
2025-12-11 14:30:10,379 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-11 14:30:10,545 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-11 14:30:10,545 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_7 v12
2025-12-11 14:30:10,545 - src.models.predict - INFO - Loaded model for horizon 7
2025-12-11 14:30:10,545 - src.models.predict - INFO - Successfully loaded all 7 production models from MLflow
2025-12-11 14:30:10,545 - __main__ - INFO - Loaded 7 production models
2025-12-11 14:30:10,545 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:10,545 - __main__ - INFO - STEP 5: Preparing Prediction Features
2025-12-11 14:30:10,545 - __main__ - INFO - ======================================================================
2025-12-11 14:30:10,545 - src.models.predict - INFO - Preparing features for prediction
2025-12-11 14:30:10,545 - src.models.predict - INFO - Base date for predictions: 2025-12-11
2025-12-11 14:30:10,554 - src.models.predict - INFO - Prepared features for 7 prediction days
2025-12-11 14:30:10,554 - src.models.predict - INFO - Prediction date range: 2025-12-12 to 2025-12-18
2025-12-11 14:30:10,554 - src.models.predict - INFO - Weather forecasts applied to prediction features
2025-12-11 14:30:10,554 - src.models.predict - INFO - Total columns in prediction features: 35
2025-12-11 14:30:10,554 - __main__ - INFO - Features prepared for next 7 days
2025-12-11 14:30:10,554 - __main__ - INFO - Each horizon has weather forecast for its target date
2025-12-11 14:30:10,554 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:10,554 - __main__ - INFO - STEP 6: Generating Predictions with Confidence Intervals
2025-12-11 14:30:10,554 - __main__ - INFO - ======================================================================
2025-12-11 14:30:10,554 - src.models.predict - INFO - Generating batch predictions for next 7 days
2025-12-11 14:30:10,554 - src.models.predict - INFO - Feature columns selected: 33 features
2025-12-11 14:30:10,574 - src.models.predict - INFO - Generated 7 predictions
2025-12-11 14:30:10,574 - src.models.predict - INFO - Prediction range: 53.0 to 70.1 patients
2025-12-11 14:30:10,576 - src.monitoring.metrics_collector - INFO - Recorded prediction metrics: 7 predictions in 0.02s
2025-12-11 14:30:10,576 - __main__ - INFO - Generated 7 predictions in 0.02s
2025-12-11 14:30:10,576 - __main__ - INFO -    Prediction range: 53.0 to 70.1 patients
2025-12-11 14:30:10,576 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:10,576 - __main__ - INFO - STEP 7: Saving Predictions
2025-12-11 14:30:10,576 - __main__ - INFO - ======================================================================
2025-12-11 14:30:10,576 - src.models.prediction_output - INFO - Saving predictions to CSV
2025-12-11 14:30:10,579 - src.models.prediction_output - INFO - Predictions saved to: data/predictions/predictions_20251211_143010.csv
2025-12-11 14:30:10,579 - src.models.prediction_output - INFO - File size: 0.8 KB, Rows: 7
2025-12-11 14:30:10,579 - __main__ - INFO - Predictions saved to CSV: data/predictions/predictions_20251211_143010.csv
2025-12-11 14:30:10,579 - src.models.prediction_output - INFO - Writing predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-11 14:30:10,601 - src.models.prediction_output - INFO - Successfully wrote 7 predictions to [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-11 14:30:10,602 - __main__ - INFO - Wrote 7 predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-11 14:30:10,602 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:10,602 - __main__ - INFO - STEP 8: Logging Metadata to MLflow
2025-12-11 14:30:10,602 - __main__ - INFO - ======================================================================
2025-12-11 14:30:10,602 - src.models.prediction_output - INFO - Logging prediction metadata to MLflow
2025-12-11 14:30:11,287 - src.models.prediction_output - INFO - Prediction metadata logged to MLflow run: a49d52430f254fba8933110d193c6a93
üèÉ View run batch_prediction_2025-12-11_14:30:10 at: http://host.docker.internal:5050/#/experiments/2/runs/a49d52430f254fba8933110d193c6a93
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/2
2025-12-11 14:30:11,342 - __main__ - INFO - Logged to MLflow run: a49d52430f254fba8933110d193c6a93
2025-12-11 14:30:11,343 - __main__ - INFO - 
======================================================================
2025-12-11 14:30:11,343 - __main__ - INFO - PREDICTION FLOW COMPLETE! 
2025-12-11 14:30:11,343 - __main__ - INFO - ======================================================================
2025-12-11 14:30:11,343 - __main__ - INFO - Average prediction: 63.4 patients
2025-12-11 14:30:11,343 - __main__ - INFO - Average interval width: 40.05558098655823
2025-12-11 14:30:11,343 - src.monitoring.metrics_collector - INFO - Recorded flow run status: prediction_flow - success
2025-12-11 14:30:11,344 - __main__ - INFO - Prediction completed successfully: 7 predictions

2025-12-11 14:30:11,722 [ERROR] Prediction STDERR:
time="2025-12-11T14:30:00Z" level=warning msg="Found orphan containers ([er-forecast-prediction-run-d1ed74f5ff8d er-forecast-training-run-f7d17f9a5ac0 er-forecast-prediction-run-aaab7f9f3565 er-forecast-training-run-4766d86e3dc8 er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.54ms
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 28926.23it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 25811.10it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 27533.72it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 29433.71it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 13451.91it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 12143.32it/s]
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 143.53it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 199.69it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 224.33it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 275.11it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 334.21it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 332.37it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 208.49it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 391.39it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 211.57it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 271.69it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 336.09it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 334.87it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 32768.00it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 1500.38it/s] 
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 485.75it/s] 
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 551.18it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 664.79it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 660.31it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 30615.36it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 25811.10it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 844.32it/s]  
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 666.85it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 684.11it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 679.02it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 33554.43it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 290.40it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 381.60it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 402.85it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 471.69it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 467.88it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 141.16it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 117.36it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 175.41it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 230.48it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 282.18it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 281.40it/s]
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
2025/12/11 14:30:10 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet


2025-12-11 14:30:11,722 [INFO] Prediction completed successfully
2025-12-11 14:30:11,722 [INFO] 10.30.53.44 - - [11/Dec/2025 14:30:11] "GET /predict HTTP/1.1" 200 -
2025-12-12 02:00:00,848 [INFO] Received /predict request
2025-12-12 02:00:13,022 [INFO] Prediction STDOUT:
2025-12-12 02:00:05,636 - src.utils.mlflow_utils - INFO - Configuring MLflow S3 backend for MinIO
2025-12-12 02:00:05,636 - src.utils.mlflow_utils - INFO - AWS credentials configured for MinIO
2025-12-12 02:00:05,636 - src.utils.mlflow_utils - INFO - MLflow S3 backend configuration completed
2025-12-12 02:00:05,636 - __main__ - INFO - ======================================================================
2025-12-12 02:00:05,636 - __main__ - INFO - STARTING ER PATIENT FORECAST PREDICTION FLOW
2025-12-12 02:00:05,636 - __main__ - INFO - ======================================================================
2025-12-12 02:00:05,636 - __main__ - INFO - Prediction base date: 2025-12-12
2025-12-12 02:00:05,636 - __main__ - INFO - Output path: data/predictions/
2025-12-12 02:00:05,636 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:05,636 - __main__ - INFO - STEP 1: Loading Latest Patient Data
2025-12-12 02:00:05,636 - __main__ - INFO - ======================================================================
2025-12-12 02:00:05,636 - __main__ - INFO - Loading data from SQL Server database using stored procedure
2025-12-12 02:00:05,637 - src.data.preprocessing - INFO - Loading data from SQL Server using stored procedure: [getVPB_Data]
2025-12-12 02:00:07,514 - src.data.preprocessing - INFO - Successfully loaded 277,788 rows from database
2025-12-12 02:00:07,548 - __main__ - INFO - Successfully loaded 277,788 rows from database
2025-12-12 02:00:07,548 - src.data.preprocessing - INFO - Removing duplicates from 277,788 rows
2025-12-12 02:00:07,565 - src.data.preprocessing - WARNING - Found 200,364 duplicate rows (72.13%)
2025-12-12 02:00:07,568 - src.data.preprocessing - INFO - After removing duplicates: 77,424 rows remain
2025-12-12 02:00:07,570 - src.data.preprocessing - INFO - Aggregating patient visits to daily counts
2025-12-12 02:00:07,633 - src.data.preprocessing - INFO - Aggregated to 1,288 days
2025-12-12 02:00:07,633 - src.data.preprocessing - INFO - Date range: 2022-05-24 00:00:00 to 2025-12-11 00:00:00
2025-12-12 02:00:07,633 - src.data.preprocessing - INFO - Average patients per day: 60.1
2025-12-12 02:00:07,633 - src.data.preprocessing - INFO - Min patients per day: 3
2025-12-12 02:00:07,633 - src.data.preprocessing - INFO - Max patients per day: 104
2025-12-12 02:00:07,635 - src.data.preprocessing - INFO - Checking for missing dates in time series
2025-12-12 02:00:07,637 - src.data.preprocessing - WARNING - Found 10 missing dates (0.77%)
2025-12-12 02:00:07,640 - src.data.preprocessing - INFO - Filled 10 missing dates with weekday median patient counts
2025-12-12 02:00:07,640 - src.data.preprocessing - INFO - Final time series: 1,298 days from 2022-05-24 to 2025-12-11
2025-12-12 02:00:07,640 - src.data.preprocessing - INFO - Detecting outliers using iqr method
2025-12-12 02:00:07,641 - src.data.preprocessing - INFO - Outlier bounds: [18, 103] patients
2025-12-12 02:00:07,641 - src.data.preprocessing - INFO - Found 4 outliers (0.31%)
2025-12-12 02:00:07,641 - src.data.preprocessing - WARNING - Outlier summary:
2025-12-12 02:00:07,641 - src.data.preprocessing - WARNING -   Below 18: 3 days
2025-12-12 02:00:07,641 - src.data.preprocessing - WARNING -   Above 103: 1 days
2025-12-12 02:00:07,642 - src.data.preprocessing - WARNING -   High: 2024-12-16 = 104 patients
2025-12-12 02:00:07,643 - src.data.preprocessing - WARNING -   Low: 2025-11-08 = 3 patients
2025-12-12 02:00:07,643 - src.data.preprocessing - WARNING -   Low: 2025-11-09 = 4 patients
2025-12-12 02:00:07,643 - src.data.preprocessing - WARNING -   Low: 2025-12-06 = 9 patients
2025-12-12 02:00:07,643 - src.data.preprocessing - INFO - Capped 4 outliers to bounds [18, 103]
2025-12-12 02:00:07,643 - __main__ - INFO - Loaded data: 1298 days up to 2025-12-11
2025-12-12 02:00:07,643 - __main__ - INFO - Data validation passed: 1298 rows, most recent date 2025-12-11 (1 days ago)
2025-12-12 02:00:07,643 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:07,644 - __main__ - INFO - STEP 2: Fetching Weather Data (Historical + Forecast)
2025-12-12 02:00:07,644 - __main__ - INFO - ======================================================================
2025-12-12 02:00:07,644 - src.data.weather_integration - INFO - Fetching weather data from 2022-05-24 to 2025-12-12
2025-12-12 02:00:07,644 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-12 02:00:08,023 - src.data.weather_integration - INFO - Successfully fetched weather data: 1299 days
2025-12-12 02:00:08,024 - src.data.weather_integration - INFO - Merging weather data with patient visit data
2025-12-12 02:00:08,026 - src.data.weather_integration - INFO - Patient data range: 2022-05-24 to 2025-12-11
2025-12-12 02:00:08,026 - src.data.weather_integration - INFO - Weather data range: 2022-05-24 to 2025-12-12
2025-12-12 02:00:08,027 - src.data.weather_integration - INFO - No missing weather data - perfect merge!
2025-12-12 02:00:08,027 - __main__ - INFO - Historical weather data: 1299 days
2025-12-12 02:00:08,027 - src.data.weather_integration - INFO - Fetching weather forecast for next 8 days
2025-12-12 02:00:08,027 - src.data.weather_integration - INFO - Location: lat=59.6099, lon=16.5448
2025-12-12 02:00:09,768 - src.data.weather_integration - INFO - Successfully fetched weather forecast: 8 days
2025-12-12 02:00:09,769 - __main__ - INFO - Weather forecast fetched: 8 days
2025-12-12 02:00:09,769 - __main__ - INFO - Forecast date range: 2025-12-12 to 2025-12-19
2025-12-12 02:00:09,769 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:09,769 - __main__ - INFO - STEP 3: Engineering Features
2025-12-12 02:00:09,769 - __main__ - INFO - ======================================================================
2025-12-12 02:00:09,769 - src.data.feature_engineering - INFO - Starting comprehensive feature engineering pipeline
2025-12-12 02:00:09,769 - src.data.feature_engineering - INFO - Adding date and time features with cyclic encoding
2025-12-12 02:00:09,773 - src.data.feature_engineering - INFO - Added 12 date/time features
2025-12-12 02:00:09,773 - src.data.feature_engineering - INFO - Adding weekend indicator
2025-12-12 02:00:09,774 - src.data.feature_engineering - INFO - Weekend days: 370/1298 (28.5%)
2025-12-12 02:00:09,774 - src.data.feature_engineering - INFO - Adding rolling statistics for windows: [3, 14, 30]
2025-12-12 02:00:09,776 - src.data.feature_engineering - INFO - Added 6 rolling statistics features
2025-12-12 02:00:09,776 - src.data.feature_engineering - INFO - Adding lag features: [1, 2, 3, 7, 14, 21, 28]
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Added 7 lag features
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Adding change features
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Added change features
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Feature engineering complete: added 28 features
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Final shape: (1298, 35)
2025-12-12 02:00:09,777 - src.data.feature_engineering - INFO - Removing rows with NaN values from feature engineering
2025-12-12 02:00:09,778 - src.data.feature_engineering - INFO - Found NaN values in 15 columns: ['patients_3d_avg', 'patients_3d_std', 'patients_14d_avg', 'patients_14d_std', 'patients_30d_avg']...
2025-12-12 02:00:09,778 - src.data.feature_engineering - INFO - Rows with NaN: 28/1298 (2.2%)
2025-12-12 02:00:09,779 - src.data.feature_engineering - INFO - Removed 28 rows with NaN values
2025-12-12 02:00:09,779 - src.data.feature_engineering - INFO - Remaining rows: 1270
2025-12-12 02:00:09,779 - __main__ - INFO - Features engineered: (1270, 35)
2025-12-12 02:00:09,779 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:09,779 - __main__ - INFO - STEP 4: Loading Production Models from MLflow
2025-12-12 02:00:09,779 - __main__ - INFO - ======================================================================
2025-12-12 02:00:09,779 - src.models.predict - INFO - Loading production models from MLflow Model Registry
2025-12-12 02:00:09,779 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_1
2025-12-12 02:00:09,843 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:10,157 - botocore.credentials - INFO - Found credentials in environment variables.
2025-12-12 02:00:10,278 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=1 days
2025-12-12 02:00:10,278 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_1 v12
2025-12-12 02:00:10,278 - src.models.predict - INFO - Loaded model for horizon 1
2025-12-12 02:00:10,278 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_2
2025-12-12 02:00:10,329 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:10,495 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=2 days
2025-12-12 02:00:10,495 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_2 v12
2025-12-12 02:00:10,495 - src.models.predict - INFO - Loaded model for horizon 2
2025-12-12 02:00:10,496 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_3
2025-12-12 02:00:10,589 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:10,755 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=3 days
2025-12-12 02:00:10,755 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_3 v12
2025-12-12 02:00:10,755 - src.models.predict - INFO - Loaded model for horizon 3
2025-12-12 02:00:10,755 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_4
2025-12-12 02:00:10,849 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:11,009 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=4 days
2025-12-12 02:00:11,009 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_4 v12
2025-12-12 02:00:11,009 - src.models.predict - INFO - Loaded model for horizon 4
2025-12-12 02:00:11,009 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_5
2025-12-12 02:00:11,103 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:11,269 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=5 days
2025-12-12 02:00:11,269 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_5 v12
2025-12-12 02:00:11,269 - src.models.predict - INFO - Loaded model for horizon 5
2025-12-12 02:00:11,269 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_6
2025-12-12 02:00:11,362 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:11,527 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=6 days
2025-12-12 02:00:11,527 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_6 v12
2025-12-12 02:00:11,528 - src.models.predict - INFO - Loaded model for horizon 6
2025-12-12 02:00:11,528 - src.utils.mlflow_utils - INFO - Loading production model: er_forecast_horizon_7
2025-12-12 02:00:11,623 - src.utils.mlflow_utils - INFO - Loading model version 12 from Production stage
2025-12-12 02:00:11,791 - src.models.lightgbm_model - INFO - Initialized LightGBMForecaster for horizon=7 days
2025-12-12 02:00:11,791 - src.utils.mlflow_utils - INFO - Model loaded successfully: er_forecast_horizon_7 v12
2025-12-12 02:00:11,791 - src.models.predict - INFO - Loaded model for horizon 7
2025-12-12 02:00:11,791 - src.models.predict - INFO - Successfully loaded all 7 production models from MLflow
2025-12-12 02:00:11,791 - __main__ - INFO - Loaded 7 production models
2025-12-12 02:00:11,791 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:11,791 - __main__ - INFO - STEP 5: Preparing Prediction Features
2025-12-12 02:00:11,791 - __main__ - INFO - ======================================================================
2025-12-12 02:00:11,791 - src.models.predict - INFO - Preparing features for prediction
2025-12-12 02:00:11,792 - src.models.predict - INFO - Base date for predictions: 2025-12-12
2025-12-12 02:00:11,800 - src.models.predict - INFO - Prepared features for 7 prediction days
2025-12-12 02:00:11,800 - src.models.predict - INFO - Prediction date range: 2025-12-13 to 2025-12-19
2025-12-12 02:00:11,800 - src.models.predict - INFO - Weather forecasts applied to prediction features
2025-12-12 02:00:11,800 - src.models.predict - INFO - Total columns in prediction features: 35
2025-12-12 02:00:11,800 - __main__ - INFO - Features prepared for next 7 days
2025-12-12 02:00:11,800 - __main__ - INFO - Each horizon has weather forecast for its target date
2025-12-12 02:00:11,800 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:11,800 - __main__ - INFO - STEP 6: Generating Predictions with Confidence Intervals
2025-12-12 02:00:11,800 - __main__ - INFO - ======================================================================
2025-12-12 02:00:11,800 - src.models.predict - INFO - Generating batch predictions for next 7 days
2025-12-12 02:00:11,800 - src.models.predict - INFO - Feature columns selected: 33 features
2025-12-12 02:00:11,820 - src.models.predict - INFO - Generated 7 predictions
2025-12-12 02:00:11,820 - src.models.predict - INFO - Prediction range: 51.5 to 71.0 patients
2025-12-12 02:00:11,822 - src.monitoring.metrics_collector - INFO - Recorded prediction metrics: 7 predictions in 0.02s
2025-12-12 02:00:11,822 - __main__ - INFO - Generated 7 predictions in 0.02s
2025-12-12 02:00:11,822 - __main__ - INFO -    Prediction range: 51.5 to 71.0 patients
2025-12-12 02:00:11,822 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:11,822 - __main__ - INFO - STEP 7: Saving Predictions
2025-12-12 02:00:11,822 - __main__ - INFO - ======================================================================
2025-12-12 02:00:11,822 - src.models.prediction_output - INFO - Saving predictions to CSV
2025-12-12 02:00:11,825 - src.models.prediction_output - INFO - Predictions saved to: data/predictions/predictions_20251212_020011.csv
2025-12-12 02:00:11,825 - src.models.prediction_output - INFO - File size: 0.8 KB, Rows: 7
2025-12-12 02:00:11,825 - __main__ - INFO - Predictions saved to CSV: data/predictions/predictions_20251212_020011.csv
2025-12-12 02:00:11,825 - src.models.prediction_output - INFO - Writing predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-12 02:00:11,895 - src.models.prediction_output - INFO - Successfully wrote 7 predictions to [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-12 02:00:11,895 - __main__ - INFO - Wrote 7 predictions to database table: [LTV_STAGE].[dbo].[ER_PREDICTION]
2025-12-12 02:00:11,895 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:11,895 - __main__ - INFO - STEP 8: Logging Metadata to MLflow
2025-12-12 02:00:11,895 - __main__ - INFO - ======================================================================
2025-12-12 02:00:11,895 - src.models.prediction_output - INFO - Logging prediction metadata to MLflow
2025-12-12 02:00:12,588 - src.models.prediction_output - INFO - Prediction metadata logged to MLflow run: 25c3c925727a4df4a4cebc248a363e93
üèÉ View run batch_prediction_2025-12-12_02:00:11 at: http://host.docker.internal:5050/#/experiments/2/runs/25c3c925727a4df4a4cebc248a363e93
üß™ View experiment at: http://host.docker.internal:5050/#/experiments/2
2025-12-12 02:00:12,642 - __main__ - INFO - Logged to MLflow run: 25c3c925727a4df4a4cebc248a363e93
2025-12-12 02:00:12,643 - __main__ - INFO - 
======================================================================
2025-12-12 02:00:12,643 - __main__ - INFO - PREDICTION FLOW COMPLETE! 
2025-12-12 02:00:12,643 - __main__ - INFO - ======================================================================
2025-12-12 02:00:12,643 - __main__ - INFO - Average prediction: 63.7 patients
2025-12-12 02:00:12,643 - __main__ - INFO - Average interval width: 39.53807512680163
2025-12-12 02:00:12,643 - src.monitoring.metrics_collector - INFO - Recorded flow run status: prediction_flow - success
2025-12-12 02:00:12,645 - __main__ - INFO - Prediction completed successfully: 7 predictions

2025-12-12 02:00:13,022 [ERROR] Prediction STDERR:
time="2025-12-12T02:00:00Z" level=warning msg="Found orphan containers ([er-forecast-prediction-run-ce30ee4647be er-forecast-prediction-run-d1ed74f5ff8d er-forecast-training-run-f7d17f9a5ac0 er-forecast-prediction-run-aaab7f9f3565 er-forecast-training-run-4766d86e3dc8 er-forecast-prediction-run-33bb70c1e8f0 er-forecast-prediction-run-a2ec1da7426c er-forecast-prediction-run-44784ef8896d er-forecast-prediction-run-2ac101094370 er-forecast-training-run-0a3b69b5751c er-forecast-prediction-run-76ac03323d4c er-forecast-training-run-30984e3fd6bf er-forecast-prediction-run-5e01dcf484c8 er-forecast-prediction-run-0acffc87653e er-forecast-prediction-run-3364c77801eb er-forecast-prediction-run-1d7dddec979d er-forecast-training-run-31362c1ffbf3 er-forecast-training-run-99347a121b7a er-forecast-prediction-run-0956609e0258 er-forecast-training-run-edda2efe2808 er-forecast-prediction-run-13d0582f9e32 er-forecast-training-run-e5a455752636 er-forecast-prediction-run-b94ef360d920 er-forecast-prediction-run-6a73fdffdbfc er-forecast-prediction-run-403bd7594d52 er-forecast-prediction-run-2f595d7331a5 er-forecast-prediction-run-de9f45ef18eb pgadmin mlflow grafana minio-init postgres prometheus minio]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up."
   Building er-patient-forecast-mlops @ file:///app
      Built er-patient-forecast-mlops @ file:///app
Uninstalled 1 package in 1ms
Installed 2 packages in 0.68ms
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 28149.69it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 25497.29it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 27176.92it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 28581.29it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 29704.70it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 24499.44it/s]
/app/src/utils/mlflow_utils.py:205: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages
  versions = client.get_latest_versions(

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 154.06it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 264.24it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 223.28it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 283.38it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 332.49it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 330.36it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 143.28it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 123.46it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 184.37it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 242.47it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 298.14it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 297.00it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 84.71it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 125.80it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 187.73it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 241.40it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 300.19it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 299.08it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 34379.54it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 287.66it/s]  
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 329.54it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 424.65it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 506.64it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 502.14it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 175.57it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 346.31it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 300.30it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 397.46it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 495.25it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 493.22it/s]

Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]
Downloading artifacts:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00, 146.35it/s]
Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 115.41it/s]
Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 168.29it/s]
Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 216.97it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 269.30it/s]
Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 268.58it/s]
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
/app/src/models/predict.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.
  pred_df.at[idx, col_name] = 1 if pred_date.dayofweek == i else 0
2025/12/12 02:00:11 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet


2025-12-12 02:00:13,022 [INFO] Prediction completed successfully
2025-12-12 02:00:13,023 [INFO] 10.30.53.44 - - [12/Dec/2025 02:00:13] "GET /predict HTTP/1.1" 200 -
